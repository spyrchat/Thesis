\chapter{Κριτική Ανασκόπηση Μεθοδολογιών Επαυξημένης Παραγωγής μέσω Ανάκτησης}
\label{ch:rag_methodologies}

\section{Εισαγωγή}

Η επαυξημένη παραγωγή μέσω ανάκτησης (Retrieval-Augmented Generation - RAG) αποτελεί μία από τις πλέον σημαντικές καινοτομίες στον τομέα της επεξεργασίας φυσικής γλώσσας, συνδυάζοντας τις δυνατότητες των μεγάλων γλωσσικών μοντέλων με εξωτερικές βάσεις δεδομένων. Η εξέλιξη των μεθοδολογιών RAG διανύει, από την πρώτη τους εμφάνιση το 2020 μέχρι σήμερα, τρεις διακριτές φάσεις ανάπτυξης, οι οποίες αντανακλούν τη συνεχή ωρίμανση του πεδίου και την προοδευτική απάντηση στους περιορισμούς των προγενέστερων προσεγγίσεων. Στο παρόν κεφάλαιο, παρουσιάζεται μια συστηματική ανάλυση των τριών κύριων παραδειγμάτων RAG: του Αρχικού (Naive), του Προηγμένου (Advanced) και του Αρθρωτού (Modular) RAG, εξετάζοντας τα τεχνικά χαρακτηριστικά, τις μεθοδολογικές προσεγγίσεις και τις πρακτικές εφαρμογές τους.

\section{Αρχικό RAG (Naive RAG)}
\label{sec:naive_rag}

\subsection{Αρχιτεκτονική και Αρχές Λειτουργίας}

Το αρχικό παράδειγμα της επαυξημένης παραγωγής μέσω ανάκτησης (Retrieval-Augmented Generation), \citep{lewis2020retrieval} αποτελεί μια γενικού σκοπού μεθοδολογία (general-purpose fine-tuning recipe) που συνδυάζει προεκπαιδευμένη παραμετρική μνήμη με μη-παραμετρική μνήμη. Η παραμετρική μνήμη υλοποιείται μέσω ενός μοντέλου <<ακολουθία σε ακολουθία>> (seq2seq), ενώ η μη-παραμετρική μνήμη αποτελείται από έναν δείκτη πυκνού διανύσματος (dense vector index).

Η διαδικασία ανάκτησης βασίζεται στη χρήση πυκνών κωδικοποιητών περάσματος κειμένου (Dense Passage Retrieval - DPR) \citep{karpukhin2020dense}. Το ερώτημα του χρήστη μετασχηματίζεται σε διανυσματική αναπαράσταση, επιτρέποντας την εύρεση σημασιολογικά όμοιων τμημάτων κειμένου από μία βάση γνώσης (knowledge base). Η αναζήτηση χρησιμοποιεί τη μετρική ομοιότητας συνημιτόνου (cosine similarity):

\begin{equation}
\text{sim}(q, d_i) = \frac{\mathbf{q} \cdot \mathbf{d_i}}{|\mathbf{q}| |\mathbf{d_i}|}
\end{equation}

όπου $\mathbf{q}$ είναι η διανυσματική αναπαράσταση του ερωτήματος και $\mathbf{d_i}$ η αντίστοιχη αναπαράσταση του i-οστού εγγράφου. Τα ανακτηθέντα τμήματα συνενώνονται με το αρχικό ερώτημα και τροφοδοτούνται στο γλωσσικό μοντέλο για την παραγωγή της απάντησης.

\subsection{Περιορισμοί και Προκλήσεις}

Η εφαρμογή του αρχικού RAG σε πραγματικά σενάρια αποκάλυψε δομικούς περιορισμούς που επηρεάζουν την αποτελεσματικότητα του συστήματος. Το φαινόμενο της «χαμένης στη μέση» πληροφορίας (lost-in-the-middle phenomenon) τεκμηριώνεται εμπειρικά από τους Liu et al. \citep{liu2023lost}. Η έρευνα καταδεικνύει την αδυναμία των γλωσσικών μοντέλων να επεξεργαστούν αποτελεσματικά μεγάλα σύνολα ανακτηθέντων εγγράφων, με την απόδοση να υποβαθμίζεται όταν οι σχετικές πληροφορίες τοποθετούνται στα μεσαία τμήματα του συμφραζομένου. Το φαινόμενο αυτό εμφανίζει μια χαρακτηριστική καμπύλη τύπου U (\ref{fig:u}), όπου η ακρίβεια ανάκτησης πληροφορίας είναι υψηλότερη για στοιχεία που βρίσκονται στην αρχή και στο τέλος του συμφραζομένου, ενώ μειώνεται αισθητά για πληροφορίες που βρίσκονται στο μέσο του. Με άλλα λόγια, τα μοντέλα τείνουν να «θυμούνται» καλύτερα τα πρώτα και τα τελευταία tokens, αγνοώντας εν μέρει εκείνα που βρίσκονται στο κεντρικό τμήμα της ακολουθίας. Το φαινόμενο αυτό παρατηρείται ακόμη και σε μοντέλα με εκτεταμένα παράθυρα συμφραζομένων, όπως τα GPT-3.5-Turbo (16K tokens) και Claude-1.3 (100K tokens), υποδηλώνοντας ότι η απλή αύξηση του μήκους του παραθύρου δεν αρκεί για την ομοιόμορφη αξιοποίηση πληροφοριών σε όλο το εύρος του συμφραζομένου.

Η απουσία μηχανισμών επαλήθευσης της σχετικότητας των ανακτηθέντων πληροφοριών αποτελεί επιπλέον περιορισμό. Το σύστημα εμπιστεύεται αποκλειστικά τη μετρική ομοιότητας για την επιλογή των εγγράφων, χωρίς περαιτέρω αξιολόγηση της πραγματικής χρησιμότητας ή ακρίβειάς τους. Αυτό οδηγεί σε παραγωγή παραπλανητικών απαντήσεων ή παραισθήσεων (hallucinations), ιδιαίτερα όταν τα ανακτηθέντα έγγραφα περιέχουν θόρυβο ή ασυνεπείς πληροφορίες.

Η στατική φύση της διαδικασίας ανάκτησης συνιστά περαιτέρω περιορισμό. Το σύστημα εκτελεί πάντοτε ανάκτηση εξωτερικών πληροφοριών, ακόμη και όταν το γλωσσικό μοντέλο διαθέτει επαρκή παραμετρική γνώση για να απαντήσει στο ερώτημα. Αυτό προκαλεί περιττή υπολογιστική επιβάρυνση, αύξηση του χρόνου απόκρισης και πιθανή εισαγωγή θορύβου στη διαδικασία παραγωγής απάντησης.

Το αρχικό RAG παρουσιάζει αδυναμίες σε περιπτώσεις όπου απαιτείται πολυβηματική συλλογιστική (multi-hop reasoning) ή σύνθεση πληροφοριών από πολλαπλές διαφορετικές πηγές. Η φύση της αρχιτεκτονικής δεν επιτρέπει την επαναληπτική βελτίωση της ανάκτησης βάσει των ενδιάμεσων αποτελεσμάτων παραγωγής. Οι περιορισμοί αυτοί οδήγησαν στην ανάπτυξη προηγμένων παραδειγμάτων RAG που αντιμετωπίζουν συστηματικά τις εντοπισμένες αδυναμίες.

Παρά τους περιορισμούς του, το αρχικό RAG καθιέρωσε την αρχή της ενσωμάτωσης εξωτερικής γνώσης στη διαδικασία παραγωγής κειμένου, θέτοντας τις βάσεις για τις μεταγενέστερες εξελίξεις στον τομέα.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.75\linewidth]{images/chapter3/U.png}
    \caption{Τα γλωσσικά μοντέλα εμφανίζουν μεροληψία θέσης (U-shaped performance): βρίσκουν ευκολότερα τις πληροφορίες όταν βρίσκονται στην αρχή ή στο τέλος του κειμένου, ενώ η απόδοσή τους πέφτει σημαντικά όταν η απάντηση βρίσκεται στη μέση \cite{liu2023lost}.}
    \label{fig:u}
\end{figure}
\section{Προηγμένο RAG (Advanced RAG)}
\label{sec:advanced_rag}

\subsection{Βελτιστοποιήσεις στη Διαδικασία Ανάκτησης}

Η μετάβαση από το αρχικό στο προηγμένο RAG χαρακτηρίζεται από την εισαγωγή εξελιγμένων τεχνικών βελτιστοποίησης που στοχεύουν στην ενίσχυση της αποτελεσματικότητας του συστήματος σε όλα τα στάδια της διαδικασίας επεξεργασίας. Αυτές οι τεχνικές οργανώνονται σε δύο κύριες κατηγορίες: τις βελτιστοποιήσεις προ-ανάκτησης που επικεντρώνονται στη βελτίωση του ερωτήματος και της δομής των δεδομένων πριν την πραγματοποίηση της αναζήτησης, και τις βελτιστοποιήσεις κατά την ανάκτηση που αφορούν τη στρατηγική και τη μεθοδολογία εύρεσης των σχετικών εγγράφων.

Στο επίπεδο της προ-ανάκτησης, η επανεγγραφή ερωτημάτων (query rewriting) αποτελεί μία από τις θεμελιώδεις τεχνικές που χρησιμοποιούν εξειδικευμένα γλωσσικά μοντέλα για τη δημιουργία πολλαπλών παραλλαγών του αρχικού ερωτήματος του χρήστη. Η προσέγγιση αυτή, όπως περιγράφεται από τους Xinbei Ma et al. \citep{ma2023query}, αυξάνει την πιθανότητα ανάκτησης σχετικών εγγράφων μέσω της διεύρυνσης του σημασιολογικού χώρου αναζήτησης, επιτρέποντας στο σύστημα να αντιμετωπίσει φαινόμενα όπως η λεξική ασυμφωνία μεταξύ ερωτήματος και εγγράφων, η διφορούμενη ορολογία, και οι υποκείμενες προθέσεις του χρήστη που δεν εκφράζονται άμεσα στο αρχικό ερώτημα. Η επανεγγραφή μπορεί να περιλαμβάνει την επέκταση του ερωτήματος με συνώνυμα και σχετικούς όρους, την αναδιατύπωσή του σε διαφορετικές γλωσσικές δομές, ή την αποσαφήνιση ασαφών ή ελλιπτικών διατυπώσεων.

Παράλληλα με την επανεγγραφή, η τεχνική HyDE (Hypothetical Document Embeddings) \citep{gao2022precise} εισάγει μια ριζικά διαφορετική φιλοσοφία στην επέκταση ερωτημάτων. Αντί να αναδιατυπώνει το ερώτημα, η μέθοδος χρησιμοποιεί ένα γλωσσικό μοντέλο για να παράγει ένα υποθετικό έγγραφο που θα μπορούσε να αποτελεί απάντηση στο ερώτημα του χρήστη. Στη συνέχεια, το σύστημα υπολογίζει την ενσωμάτωση αυτού του υποθετικού εγγράφου και το χρησιμοποιεί ως βάση για την ανάκτηση από τη συλλογή. Η θεμελιώδης διαίσθηση πίσω από την προσέγγιση βασίζεται στην παρατήρηση ότι οι ενσωματώσεις των εγγράφων τείνουν να είναι σημασιολογικά πιο όμοιες μεταξύ τους από ό,τι οι ενσωματώσεις των ερωτημάτων με τις ενσωματώσεις των εγγράφων. Επομένως, η χρήση ενός υποθετικού εγγράφου ως μεσάζοντα μειώνει το σημασιολογικό χάσμα και βελτιώνει την ανάκληση. Παρότι το υποθετικό έγγραφο μπορεί να περιέχει ανακρίβειες ή παραισθήσεις, η συνολική διαδικασία αποδεικνύεται αποτελεσματική επειδή το σύστημα ανάκτησης αναζητά πραγματικά έγγραφα με παρόμοιο σημασιολογικό περιεχόμενο, όχι ακριβείς αντιστοιχίες.

Μία άλλη τεχνική για σύνθετα ερωτήματα που απαιτούν συλλογισμό πολλαπλών βημάτων είναι η αποσύνθεση ερωτημάτων (query decomposition). Αποτελεί κρίσιμη τεχνική που διασπά ένα ερώτημα πολλαπλού βήματος (multi-hop) σε ακολουθία απλούστερων ερωτημάτων μονού βήματος. Η προσέγγιση αυτή, εμπνευσμένη από το πλαίσιο StrategyQA, επιτρέπει στο σύστημα να ανακτά πληροφορίες σταδιακά, κατασκευάζοντας την τελική απάντηση μέσω αλυσιδωτού συλλογισμού. Για παράδειγμα, ένα ερώτημα όπως <<Ποια είναι η πρωτεύουσα της χώρας όπου γεννήθηκε ο εφευρέτης του τηλεφώνου;>> αποσυντίθεται στα επιμέρους ερωτήματα: <<Ποιος ήταν ο εφευρέτης του τηλεφώνου;>>, <<Πού γεννήθηκε αυτό το άτομο;>>, και <<Ποια είναι η πρωτεύουσα αυτής της χώρας;>>. Κάθε υπο-ερώτημα απευθύνεται στο σύστημα ανάκτησης ξεχωριστά, και οι απαντήσεις συντίθενται για την παραγωγή της τελικής απόκρισης.

Πέρα από τη βελτιστοποίηση των ερωτημάτων, η υβριδική αναζήτηση (hybrid search) αντιπροσωπεύει μια ουσιώδη εξέλιξη στο επίπεδο της ανάκτησης, συνδυάζοντας τα πλεονεκτήματα πυκνών (dense) και αραιών (sparse) μεθόδων. Οι πυκνές μέθοδοι, που βασίζονται σε διανυσματικές αναπαραστάσεις υψηλής διάστασης παραγόμενες από νευρωνικά δίκτυα, υπερέχουν στη σύλληψη της σημασιολογικής ομοιότητας και μπορούν να αναγνωρίσουν σχετικά έγγραφα ακόμα και όταν δεν υπάρχει λεξική επικάλυψη με το ερώτημα. Οι αραιές μέθοδοι, όπως το κλασικό BM25, διατηρούν ισχυρή απόδοση στην ακριβή λεξική αντιστοίχιση και είναι ιδιαίτερα αποτελεσματικές όταν τα ερωτήματα περιέχουν εξειδικευμένη ορολογία, ονόματα οντοτήτων, ή τεχνικούς όρους που πρέπει να αντιστοιχιστούν με ακρίβεια. Ο συνδυασμός των δύο προσεγγίσεων επιτυγχάνει σημαντική βελτίωση της ανάκλησης σε σχέση με τη χρήση μεμονωμένων μεθόδων.

Η μαθηματική θεμελίωση της υβριδικής βαθμολόγησης μπορεί να επιτευχθεί με διάφορους τρόπους. Μία απλή προσέγγιση είναι η γραμμική συνδυασμός κανονικοποιημένων βαθμολογιών:

\begin{equation}
    S_{\text{hybrid}} = (1-\alpha) \cdot \text{norm}(S_{\text{BM25}}) + \alpha \cdot \text{norm}(S_{\text{vector}})
\end{equation}

όπου $\alpha \in [0,1]$ ελέγχει την ισορροπία μεταξύ λεξιλογικής και σημασιολογικής αντιστοίχισης, ενώ η συνάρτηση $\text{norm}(\cdot)$ εξασφαλίζει την κανονικοποίηση των βαθμολογιών σε συγκρίσιμο εύρος τιμών. Ωστόσο, η κανονικοποίηση βαθμολογιών από διαφορετικές μεθόδους μπορεί να εισάγει προκαταλήψεις (biases) και να είναι υπολογιστικά απαιτητική.

Μια καλύτερη εναλλακτική προσέγγιση είναι ο αλγόριθμος Reciprocal Rank Fusion (RRF) \citep{cormack2009reciprocal}, ο οποίος αποφεύγει εντελώς την ανάγκη κανονικοποίησης, αφού βασίζεται αποκλειστικά στις σχετικές θέσεις (ranks) των εγγράφων σε κάθε λίστα αποτελεσμάτων. Η μέθοδος ορίζεται ως:

\begin{equation}
    \text{RRF}(d) = \sum_{r \in R} \frac{1}{k + \text{rank}_r(d)}
    \label{eq:rrf}
\end{equation}

όπου $\text{rank}_r(d)$ είναι η θέση του εγγράφου $d$ στη λίστα αποτελεσμάτων $r$ και $k$ είναι μια σταθερά που συνήθως λαμβάνει την τιμή 60. Η παράμετρος $k$ εξυπηρετεί διπλό σκοπό: αποτρέπει την κυριαρχία των πρώτων θέσεων και εξασφαλίζει ότι η συνεισφορά κάθε λίστας μειώνεται σταδιακά με τη θέση. Το RRF έχει αποδειχθεί αποτελεσματικό σε ένα ευρύ φάσμα σεναρίων και είναι ιδιαίτερα ανθεκτικό στις διακυμάνσεις της ποιότητας των επιμέρους μεθόδων ανάκτησης.

Παράλληλα με τον συνδυασμό μεθόδων, η εισαγωγή προσαρμοστικών στρατηγικών ανάκτησης επιτρέπει στο σύστημα να προσαρμόζει δυναμικά παραμέτρους όπως ο αριθμός των ανακτηθέντων εγγράφων ανάλογα με την πολυπλοκότητα του ερωτήματος, τη διαθεσιμότητα σχετικών πληροφοριών στη βάση γνώσης, και την εμπιστοσύνη του συστήματος στην ποιότητα των αρχικών αποτελεσμάτων. Αυτή η δυναμική προσαρμογή αποτρέπει τόσο την υποφόρτωση με ανεπαρκείς πληροφορίες όσο και την υπερφόρτωση με θόρυβο και μη σχετικό περιεχόμενο.

\begin{algorithm}[H]
\caption{Συγχώνευση Κατατάξεων με Reciprocal Rank Fusion (RRF)}
\label{alg:rrf}
\begin{algorithmic}[1]
\Require Λίστες κατάταξης από $M$ διαφορετικούς ανακτητές: $\mathcal{R}=\{R_1,\ldots,R_M\}$, παράμετρος $k>0$ (συνήθως $k=60$), προαιρετικά επιθυμητό top-$K$.
\Ensure Μία ενιαία, συγχωνευμένη λίστα εγγράφων $S$.

\State $U \gets \bigcup_{m=1}^{M} \{ d \mid d \in R_m \}$ \Comment{Όλα τα έγγραφα που εμφανίστηκαν}
\State Για κάθε $d \in U$: \texttt{score[$d$]} $\gets 0$

\For{$m=1$ \textbf{έως} $M$}
  \For{$r=1$ \textbf{έως} $|R_m|$}
    \State $d \gets R_m[r]$ \Comment{Το έγγραφο στη θέση $r$ του ανακτητή $m$}
    \State \texttt{score[$d$]} $\gets$ \texttt{score[$d$]} $+ \dfrac{1}{k + r}$
  \EndFor
\EndFor

\State $S \gets$ ταξινόμησε τα στοιχεία του $U$ κατά φθίνουσα \texttt{score[$d$]}
\If{δόθηκε $K$}
  \State $S \gets$ κράτα τα πρώτα $K$ στοιχεία του $S$
\EndIf

\State \Return $S$
\end{algorithmic}
\end{algorithm}

\subsection{Μηχανισμοί Επεξεργασίας και Βελτίωσης Ανακτηθέντων Εγγράφων}

Μετά την αρχική ανάκτηση, τα συστήματα προηγμένου RAG εφαρμόζουν μια σειρά τεχνικών μετα-επεξεργασίας που στοχεύουν στη βελτίωση της ποιότητας και της συνάφειας των εγγράφων που τελικά τροφοδοτούνται στο γλωσσικό μοντέλο. Αυτές οι τεχνικές αντιμετωπίζουν τρία θεμελιώδη προβλήματα: την ανακριβή αρχική κατάταξη που μπορεί να τοποθετεί λιγότερο σχετικά έγγραφα σε προεξέχουσες θέσεις, την παρουσία πλεονάζουσας ή μη σχετικής πληροφορίας που εισάγει θόρυβο, και την υπερβολική μακροσκέλεια του πλαισίου που επιβαρύνει το γλωσσικό μοντέλο και αυξάνει το υπολογιστικό κόστος.

Η επανακατάταξη (reranking) αποτελεί την πρώτη γραμμή άμυνας κατά του προβλήματος της ανακριβούς αρχικής κατάταξης. Οι διασταυρούμενοι κωδικοποιητές (cross-encoders), όπως περιγράφονται από τους Nogueira et al. \citep{nogueira2019passage}, επεξεργάζονται το ερώτημα και κάθε υποψήφιο έγγραφο από κοινού, επιτρέποντας στο μοντέλο να αξιολογήσει τη σχετικότητά τους μέσω πλήρους διασταυρωμένης προσοχής (cross-attention) μεταξύ όλων των tokens. Αυτή η προσέγγιση αντιτίθεται στους παραδοσιακούς bi-encoders που κωδικοποιούν το ερώτημα και το έγγραφο ανεξάρτητα και στη συνέχεια υπολογίζουν την ομοιότητα των ενσωματώσεών τους. Η βαθύτερη σημασιολογική κατανόηση που προσφέρουν οι διασταυρωμένοι κωδικοποιητές οδηγεί σε σημαντικά ανώτερη απόδοση. Συγκεκριμένα, η εφαρμογή επανακατάταξης διασταυρωμένου κωδικοποιητή βασισμένου σε BERT στο σύνολο δεδομένων MS MARCO επέτυχε Mean Reciprocal Rank στη δεκάδα (MRR@10) περίπου 36.5 τοις εκατό για το BERTlarge μοντέλο, υπερβαίνοντας σημαντικά την απόδοση προηγούμενων μεθόδων. Το υπολογιστικό κόστος των διασταυρωμένων κωδικοποιητών είναι σημαντικά υψηλότερο από τους bi-encoders, καθώς απαιτείται ξεχωριστή επεξεργασία για κάθε ζεύγος ερωτήματος-εγγράφου, αλλά αυτό το κόστος είναι αποδεκτό για την επανακατάταξη ενός περιορισμένου συνόλου υποψηφίων που έχουν ήδη προεπιλεγεί από ταχύτερες μεθόδους πρώτου σταδίου.

Πέρα από την επανακατάταξη, η δυναμική επιλογή του αριθμού των εγγράφων που θα διατηρηθούν αποτελεί κρίσιμη απόφαση που επηρεάζει τόσο την ποιότητα όσο και την αποδοτικότητα του συστήματος. Οι στατικές προσεγγίσεις που διατηρούν σταθερό αριθμό εγγράφων (π.χ., πάντα τα πρώτα k) δεν λαμβάνουν υπόψη τη σημαντική διακύμανση στην ποιότητα και τη διαθεσιμότητα σχετικών πληροφοριών μεταξύ διαφορετικών ερωτημάτων. Ένα ερώτημα για το οποίο υπάρχουν πολλά άρτια σχετικά έγγραφα μπορεί να επωφεληθεί από τη διατήρηση περισσότερων αποτελεσμάτων, ενώ ένα ερώτημα με λίγα οριακά σχετικά έγγραφα θα έπρεπε να περιοριστεί σε μικρότερο σύνολο για την αποφυγή θορύβου. Οι δυναμικοί μηχανισμοί φιλτραρίσματος χρησιμοποιούν κατώφλια βαθμολογίας σχετικότητας, αναλύουν τη διασπορά των βαθμολογιών, ή εφαρμόζουν μοντέλα αξιολόγησης σχετικότητας για να καθορίσουν προσαρμοστικά το βέλτιστο σύνολο εγγράφων για κάθε ερώτημα.

Μια συχνά παραβλεπόμενη αλλά ουσιώδης τεχνική είναι η επαύξηση αποσπασμάτων (passage augmentation), η οποία αντιμετωπίζει το πρόβλημα της αποκοπής σημασιολογικού πλαισίου που προκύπτει από τη διαδικασία της τμηματοποίησης (chunking). Όταν ένα μεγάλο έγγραφο διαιρείται σε μικρότερα αποσπάσματα για την αποδοτικότερη ανάκτηση, συχνά χάνονται σημαντικές πληροφορίες που βρίσκονται ακριβώς πριν ή μετά τα όρια του αποσπάσματος. Η τεχνική prev-next augmentation εμπλουτίζει κάθε ανακτηθέν απόσπασμα προσθέτοντας το αμέσως προηγούμενο και επόμενο τμήμα από το πηγαίο έγγραφο, διατηρώντας έτσι τη σημασιολογική συνοχή και παρέχοντας επαρκές πλαίσιο για την κατανόηση. Αυτή η απλή αλλά αποτελεσματική στρατηγική μπορεί να βελτιώσει σημαντικά την ποιότητα των παραγόμενων απαντήσεων χωρίς να απαιτεί περίπλοκες αλλαγές στην αρχιτεκτονική του συστήματος.

Η συμπίεση πλαισίου (context compression) αντιπροσωπεύει μια διαφορετική φιλοσοφία που αντί να επιλέγει ποια έγγραφα να διατηρήσει, εστιάζει στην εξάλειψη μη ουσιωδών πληροφοριών εντός των επιλεγμένων εγγράφων. Η υπερφόρτωση με πληροφορίες μπορεί να επηρεάσει αρνητικά την απόδοση των γλωσσικών μοντέλων μέσω διαφόρων μηχανισμών: η παρουσία μεγάλου όγκου μη σχετικών πληροφοριών μπορεί να αποσπάσει την προσοχή του μοντέλου από τις πραγματικά σημαντικές πληροφορίες, το φαινόμενο "lost in the middle" οδηγεί τα μοντέλα να εστιάζουν δυσανάλογα στην αρχή και το τέλος μακρών πλαισίων παραβλέποντας κρίσιμες πληροφορίες στη μέση, και το αυξημένο πλήθος tokens οδηγεί σε υψηλότερο υπολογιστικό και οικονομικό κόστος. Το πλαίσιο LLMLingua \citep{jiang2023llmlingua} και οι επεκτάσεις του χρησιμοποιούν μικρά γλωσσικά μοντέλα, όπως τα GPT-2 Small ή LLaMA-7B, για να εντοπίσουν και να αφαιρέσουν μη σημαντικά tokens από το πλαίσιο. Η μέθοδος επιτυγχάνει compression ratios που κυμαίνονται από 2x έως 10x χωρίς σημαντική απώλεια πληροφορίας, μετασχηματίζοντας το πλαίσιο σε μια μορφή που μπορεί να φαίνεται δυσανάγνωστη για ανθρώπους αλλά παραμένει κατανοητή από τα μεγάλα γλωσσικά μοντέλα. Εναλλακτικές προσεγγίσεις όπως το RECOMP εκπαιδεύουν εξειδικευμένα μοντέλα συμπύκνωσης πληροφοριών (information condensers) μέσω αντικρουόμενης μάθησης (contrastive learning), όπου το μοντέλο μαθαίνει να διατηρεί τις ουσιώδεις πληροφορίες ενώ απορρίπτει τον θόρυβο συγκρίνοντας θετικά παραδείγματα σχετικών αποσπασμάτων με αρνητικά παραδείγματα μη σχετικών.

\subsection{Προσαρμοστικές Στρατηγικές Ανάκτησης}

Οι προσαρμοστικές στρατηγικές ανάκτησης αντιπροσωπεύουν μια ριζική αλλαγή παραδείγματος στη φιλοσοφία του RAG, μετακινώντας την ευθύνη της απόφασης για το πότε και πώς να ανακτηθούν πληροφορίες από το στατικό σχεδιασμό του συστήματος στη δυναμική κρίση του γλωσσικού μοντέλου. Αντί να ακολουθούν μια σταθερή διαδικασία ανάκτησης για κάθε ερώτημα, αυτά τα συστήματα αξιολογούν συνεχώς την ανάγκη για εξωτερικές πληροφορίες και προσαρμόζουν τη συμπεριφορά τους ανάλογα.

Το πλαίσιο Self-RAG \citep{asai2023selfrag} υλοποιεί αυτήν την ιδέα μέσω της εισαγωγής ειδικών token στοχασμού (reflection tokens) που λειτουργούν ως μετα-γνωστικοί μηχανισμοί επιτρέποντας στο μοντέλο να αναστοχαστεί πάνω στην ποιότητα και την αναγκαιότητα της ανάκτησης. Τα tokens στοχασμού οργανώνονται σε δύο κατηγορίες: τα "tokens ανάκτησης" που καθορίζουν πότε το σύστημα πρέπει να ενεργοποιήσει την ανάκτηση, και τα "tokens κριτικής" που αξιολογούν τη σχετικότητα των ανακτηθέντων αποσπασμάτων και την ποιότητα των παραγόμενων απαντήσεων. Κατά τη διάρκεια της παραγωγής, το μοντέλο μπορεί να αποφασίσει αυτόνομα να ενεργοποιήσει την ανάκτηση όταν εντοπίζει κενά στη γνώση του ή χαμηλή εμπιστοσύνη στις παραγόμενες πληροφορίες. Μετά την ανάκτηση, το μοντέλο αξιολογεί κριτικά κάθε ανακτηθέν απόσπασμα για τη σχετικότητά του με το ερώτημα και χρησιμοποιεί αυτήν την αξιολόγηση για να καθοδηγήσει τη διαδικασία παραγωγής. Η προσέγγιση αυτή επιτρέπει στο σύστημα να εκτελεί αναζήτηση δέσμης σε επίπεδο αποσπασμάτων (fragment-level beam search) πάνω από πολλαπλά αποσπάσματα, επιλέγοντας τη συνεκτικότερη ακολουθία παραγωγής. Οι βαθμολογίες κριτικής μπορούν να ενημερώνουν τις βαθμολογίες των υπο-ακολουθιών, με τη δυνατότητα προσαρμογής των βαρών κατά το στάδιο απόφασης για την εξατομίκευση της συμπεριφοράς του μοντέλου.

Το πλαίσιο FLARE (Active Retrieval Augmented Generation) \citep{jiang2023active} υιοθετεί μια διαφορετική στρατηγική βασιζόμενη στην παρακολούθηση της εμπιστοσύνης του μοντέλου κατά την παραγωγή. Το σύστημα υπολογίζει συνεχώς την πιθανότητα των επόμενων tokens που παράγει το γλωσσικό μοντέλο, χρησιμοποιώντας αυτές τις πιθανότητες ως δείκτες εμπιστοσύνης. Όταν η εμπιστοσύνη πέφτει κάτω από ένα προκαθορισμένο κατώφλι, υποδεικνύοντας αβεβαιότητα ή έλλειψη γνώσης, το FLARE ενεργοποιεί αυτόματα την ανάκτηση για να αναζητήσει πρόσθετες πληροφορίες που θα υποστηρίξουν την παραγωγή. Αυτή η προληπτική στρατηγική εξασφαλίζει ότι το σύστημα αναζητά βοήθεια ακριβώς όταν τη χρειάζεται, αποφεύγοντας τόσο την περιττή ανάκτηση για απλά ερωτήματα που το μοντέλο μπορεί να απαντήσει από τη γνώση του, όσο και την ανεπαρκή ανάκτηση για σύνθετα ερωτήματα που απαιτούν εξωτερική τεκμηρίωση.

Οι προσαρμοστικές στρατηγικές εντάσσονται στη γενικότερη τάση των αυτόνομων συστημάτων που χρησιμοποιούν γλωσσικά μοντέλα ως πράκτορες με δυνατότητα ενεργού κρίσης και χρήσης εργαλείων. Παρόμοια συστήματα όπως το WebGPT ενσωματώνουν πλαίσια ενισχυτικής μάθησης για να εκπαιδεύσουν το μοντέλο να χρησιμοποιεί αυτόνομα μηχανές αναζήτησης κατά τη διάρκεια της παραγωγής κειμένου, αυτοματοποιώντας την πλοήγηση μέσω ειδικών tokens που διευκολύνουν ενέργειες όπως η υποβολή ερωτημάτων, η περιήγηση αποτελεσμάτων, και η παραπομπή σε πηγές. Αυτή η μετάβαση από στατικούς προ-σχεδιασμένους αγωγούς σε δυναμικά προσαρμοστικά συστήματα αντιπροσωπεύει την εξέλιξη του RAG από ένα παθητικό εργαλείο ανάκτησης σε ένα ενεργό σύστημα λογικής που μπορεί να αξιολογεί τις πληροφοριακές του ανάγκες και να ενεργεί αναλόγως.

\section{Αρθρωτό RAG (Modular RAG)}
\label{sec:modular_rag}

\subsection{Ιεραρχική Ανάκτηση και το Παράδειγμα RAPTOR}

Η ιεραρχική οργάνωση της πληροφορίας αποτελεί θεμελιώδη καινοτομία στο πλαίσιο του Αρθρωτού RAG, επιτρέποντας την ανάκτηση σε πολλαπλά επίπεδα αφαίρεσης. Το σύστημα RAPTOR (Recursive Abstractive Processing for Tree-Organized Retrieval) \citep{sarthi2024raptor} εισάγει μία ριζικά διαφορετική προσέγγιση στην οργάνωση και ανάκτηση πληροφοριών από εκτενή έγγραφα.

Η αρχιτεκτονική του RAPTOR βασίζεται στην αναδρομική κατασκευή δενδρικής δομής μέσω τριών βασικών λειτουργιών: της ενσωμάτωσης (embedding), της ομαδοποίησης (clustering) και της αφαιρετικής περίληψης (abstractive summarization). Η διαδικασία ξεκινά από την τμηματοποίηση του εγγράφου σε τμήματα σταθερού μήκους (συνήθως 100 tokens), τα οποία αποτελούν τα φύλλα του δέντρου. Στη συνέχεια, εφαρμόζεται επαναληπτικά η ακόλουθη διαδικασία:

\begin{enumerate}
    \item \textbf{Διανυσματική Αναπαράσταση}: Κάθε τμήμα κειμένου μετασχηματίζεται σε πυκνή διανυσματική αναπαράσταση μέσω προεκπαιδευμένων κωδικοποιητών.
    \item \textbf{Ομαδοποίηση}: Εφαρμόζεται αλγόριθμος Γκαουσιανού μοντέλου μίξης (Gaussian Mixture Model, GMM) για την ταυτοποίηση ομάδων σημασιολογικά συσχετισμένων τμημάτων.
    \item \textbf{Αφαιρετική Περίληψη}: Κάθε ομάδα συνοψίζεται από γλωσσικό μοντέλο, παράγοντας ένα νέο κείμενο που αποτελεί τον γονικό κόμβο της ομάδας.
\end{enumerate}

Η διαδικασία επαναλαμβάνεται αναδρομικά, δημιουργώντας επίπεδα αυξανόμενης αφαίρεσης, μέχρι να καταστεί αδύνατη η περαιτέρω ομαδοποίηση. Το αποτέλεσμα είναι μία ιεραρχική δομή όπου:
\begin{itemize}
    \item Οι κόμβοι-φύλλα περιέχουν το πρωτότυπο, λεπτομερές περιεχόμενο
    \item Οι ενδιάμεσοι κόμβοι αποθηκεύουν περιλήψεις μεσαίου επιπέδου
    \item Η ρίζα αντιπροσωπεύει μία ολιστική, υψηλού επιπέδου περίληψη του εγγράφου
\end{itemize}

Κατά τη διαδικασία ανάκτησης, το σύστημα υπολογίζει τη σημασιολογική ομοιότητα μεταξύ του ερωτήματος και όλων των κόμβων του δέντρου (collapsed tree retrieval). Αυτή η προσέγγιση επιτρέπει στο σύστημα να ανακτά πληροφορίες σε διαφορετικά επίπεδα λεπτομέρειας ανάλογα με τη φύση του ερωτήματος:

\begin{equation}
    \text{sim}(q, n_i) = \cos(\mathbf{E}_q, \mathbf{E}_{n_i})
\end{equation}

όπου $\mathbf{E}_q$ είναι η ενσωμάτωση του ερωτήματος και $\mathbf{E}_{n_i}$ η ενσωμάτωση του i-οστού κόμβου.

Πειραματικά αποτελέσματα επιδεικνύουν σημαντικές βελτιώσεις σε καθήκοντα που απαιτούν σύνθετη, πολυβηματική συλλογιστική. Στο benchmark QASPER, το RAPTOR σε συνδυασμό με το GPT-4 επιτυγχάνει F1-score 55.7\%, υπερβαίνοντας σημαντικά τις παραδοσιακές μεθόδους ανάκτησης όπως το DPR (53.0\%) και τη χρήση μόνο των τίτλων και περιλήψεων (22.2\%). Στο QuALITY benchmark, η απόλυτη ακρίβεια βελτιώνεται κατά 20\% σε σχέση με τις κορυφαίες προηγούμενες μεθόδους.

Η αρχιτεκτονική του RAPTOR αντιμετωπίζει αποτελεσματικά τον θεμελιώδη περιορισμό των παραδοσιακών RAG συστημάτων που ανακτούν μόνο σύντομα, συνεχόμενα τμήματα κειμένου. Παρέχοντας πρόσβαση σε πολλαπλά επίπεδα πληροφορίας - από λεπτομερείς αναφορές μέχρι ολιστικές περιλήψεις - το σύστημα διευκολύνει τη βαθύτερη κατανόηση και σύνθεση πληροφοριών από εκτενή έγγραφα. Ωστόσο, η προσέγγιση παρουσιάζει σημαντικό υπολογιστικό κόστος κατά την κατασκευή του δέντρου και απαιτεί ιδιαίτερη προσοχή στην επιλογή των παραμέτρων ομαδοποίησης και των prompts περίληψης για να διασφαλιστεί η ποιότητα των παραγόμενων συνόψεων.

\subsection{Πολυβηματική Συλλογιστική και Λογική Ανάκτηση}

Η ανάπτυξη συστημάτων πολυβηματικής συλλογιστικής στο πλαίσιο του αρθρωτού RAG αντιμετωπίζει την πρόκληση της σύνθετης ερωταπόκρισης που απαιτεί συνδυασμό πληροφοριών από πολλαπλές πηγές. Το σύστημα HopRAG \citep{chen2024hoprag} κατασκευάζει δυναμικά γραφήματα αποσπασμάτων όπου:

\begin{itemize}
    \item Οι κόμβοι αντιπροσωπεύουν τμήματα κειμένου (text chunks)
    \item Οι ακμές δημιουργούνται μέσω ψεύδο-ερωτημάτων παραγόμενα από μεγάλα γλωσσικά μοντέλα, που συνδέουν σημασιολογικά συσχετισμένα τμήματα
    \item Η διάσχιση του γραφήματος ακολουθεί τη λογική ανέκτησε-συλλογίσου-αφαίρεσε (retrieve-reason-prune)
\end{itemize}

Η διαδικασία πολυβηματικής συλλογιστικής μοντελοποιείται ως πρόβλημα βέλτιστης διαδρομής στο γράφημα:

\begin{equation}
    P^* = \arg\max_{P \in \mathcal{P}} \prod_{(v_i, v_j) \in P} w(v_i, v_j) \cdot r(v_j, q)
\end{equation}

όπου $P$ είναι μια διαδρομή στο γράφημα, $w(v_i, v_j)$ το βάρος της ακμής και $r(v_j, q)$ η σχετικότητα του κόμβου $v_j$ με το ερώτημα $q$.

\subsection{Μετρικές Ανάκτησης Πληροφοριών}
\label{subsec:evaluation-metrics}
Η αξιολόγηση της απόδοσης των συστημάτων RAG απαιτεί τη χρήση εξειδικευμένων μετρικών που καλύπτουν τόσο την ποιότητα ανάκτησης όσο και την ακρίβεια παραγωγής. Οι κλασσικές μετρικές ανάκτησης πληροφοριών, οι οποίες έχουν αναπτυχθεί και επικυρωθεί στο ευρύτερο πεδίο της Ανάκτησης Πληροφοριών (Information Retrieval), αποτελούν τη θεμελιώδη βάση για την αξιολόγηση του ανακτητή στα σύγχρονα συστήματα RAG.

Η \textbf{Ακρίβεια (Precision)} και η \textbf{Ανάκληση (Recall)} αποτελούν θεμελιώδεις μετρικές που ποσοτικοποιούν την ικανότητα του συστήματος ανάκτησης να εντοπίζει σχετικά έγγραφα από μια συλλογή. Η ακρίβεια εκφράζει το κλάσμα των ανακτηθέντων εγγράφων που είναι πραγματικά σχετικά με το ερώτημα του χρήστη, ενώ η ανάκληση εκφράζει το κλάσμα των συνολικά σχετικών εγγράφων που επιτυχώς ανακτήθηκαν από το σύστημα. Μαθηματικά, οι μετρικές αυτές ορίζονται ως:

\begin{equation}
    \text{Precision@k} = \frac{|\text{Relevant} \cap \text{Retrieved}_k|}{k}
    \label{eq:precision}
\end{equation}

\begin{equation}
    \text{Recall@k} = \frac{|\text{Relevant} \cap \text{Retrieved}_k|}{|\text{Relevant}|}
    \label{eq:recall}
\end{equation}

όπου $\text{Retrieved}_k$ αντιπροσωπεύει το σύνολο των πρώτων $k$ ανακτηθέντων εγγράφων και $\text{Relevant}$ το σύνολο όλων των σχετικών εγγράφων στη συλλογή. Ο αρμονικός μέσος των δύο μετρικών δίνει το \textbf{F1-Score}, το οποίο προσφέρει μια ισορροπημένη εκτίμηση της απόδοσης, αποφεύγοντας ακραίες τιμές σε μία μόνο διάσταση:

\begin{equation}
    \text{F1@k} = 2 \cdot \frac{\text{Precision@k} \cdot \text{Recall@k}}{\text{Precision@k} + \text{Recall@k}}
    \label{eq:f1}
\end{equation}

Η μετρική \textbf{Success@k} (ή \textbf{Hit Rate@k}) αξιολογεί το ποσοστό των ερωτημάτων για τα οποία τουλάχιστον ένα σχετικό έγγραφο περιλαμβάνεται στα πρώτα $k$ ανακτηθέντα αποτελέσματα. Σε αντίθεση με τις μετρικές ακρίβειας και ανάκλησης που αποτυπώνουν ποσοτικά τον βαθμό συνάφειας, η Success@k εστιάζει στη δυαδική επιτυχία της ανάκτησης ανά ερώτημα, παρέχοντας μια καθαρή ένδειξη για το αν το σύστημα «βρήκε» έστω ένα σωστό τεκμήριο μέσα στα ανακτηθέντα. Ορίζεται ως:

\begin{equation}
\text{Success@k} = \frac{1}{|Q|} \sum_{i=1}^{|Q|} \mathbb{I}\left[|\text{Relevant}i \cap \text{Retrieved}{i,k}| > 0\right]
\label{eq:success}
\end{equation}

όπου $\mathbb{I}[\cdot]$ είναι η ενδεικτική συνάρτηση, η οποία λαμβάνει τιμή $1$ αν για το ερώτημα $i$ έχει ανακτηθεί τουλάχιστον ένα σχετικό τεκμήριο στα πρώτα $k$ αποτελέσματα, και $0$ διαφορετικά.

Η \textbf{Mean Reciprocal Rank (MRR)} \citep{voorhees1999trec} επικεντρώνεται στην αξιολόγηση της ικανότητας ενός συστήματος να κατατάσσει το πρώτο σχετικό έγγραφο όσο το δυνατόν ψηλότερα στη λίστα αποτελεσμάτων. Η μετρική αυτή είναι ιδιαίτερα σημαντική σε εφαρμογές όπου ο χρήστης ενδιαφέρεται για την άμεση εύρεση μιας σωστής απάντησης, όπως στα συστήματα ερωτοαπόκρισης. Ορίζεται ως:

\begin{equation}
    \text{MRR} = \frac{1}{|Q|} \sum_{i=1}^{|Q|} \frac{1}{\text{rank}_i}
    \label{eq:mrr}
\end{equation}

όπου $\text{rank}_i$ είναι η θέση του πρώτου σχετικού εγγράφου για το ερώτημα $i$ και $|Q|$ το πλήθος των ερωτημάτων στο σύνολο αξιολόγησης.

Το \textbf{Mean Average Precision (MAP)} \citep{manning2008introduction} επεκτείνει την ιδέα του MRR, λαμβάνοντας υπόψη όλες τις θέσεις των σχετικών εγγράφων στη λίστα αποτελεσμάτων, αντί μόνο της πρώτης. Για κάθε ερώτημα, υπολογίζεται η \textit{μέση ακρίβεια} (\textit{Average Precision, AP}), δηλαδή ο μέσος όρος της ακρίβειας στις θέσεις όπου εντοπίζονται σχετικά έγγραφα. Η μέση ακρίβεια για το ερώτημα $q_i$ ορίζεται ως:
\begin{equation}
    \text{AP}(q_i) = \frac{1}{|\text{Relevant}_i|} 
    \sum_{k=1}^{n} \text{Precision@k}(q_i) \cdot \text{rel}_i(k)
    \label{eq:ap}
\end{equation}
όπου $\text{rel}_i(k)$ είναι μια δυαδική μεταβλητή που λαμβάνει τιμή $1$ αν το έγγραφο στη θέση $k$ είναι σχετικό, και $0$ διαφορετικά. Η τελική τιμή του MAP προκύπτει ως ο μέσος όρος των τιμών AP για όλα τα ερωτήματα:

\begin{equation}
    \text{MAP} = \frac{1}{|Q|} \sum_{i=1}^{|Q|} \text{AP}(q_i)
    \label{eq:map}
\end{equation}

Η μετρική MAP είναι ιδιαίτερα χρήσιμη όταν για κάθε ερώτημα υπάρχουν πολλαπλά σχετικά τεκμήρια, καθώς μετρά τόσο την ικανότητα εντοπισμού όσο και την ορθότητα κατάταξής τους.

Το \textbf{Normalized Discounted Cumulative Gain (NDCG)} \citep{jarvelin2002cumulated} αντιπροσωπεύει μια προηγμένη μετρική που επιτρέπει την αξιολόγηση συστημάτων όπου η σχετικότητα δεν είναι δυαδική αλλά βαθμολογημένη. Η μετρική λαμβάνει υπόψη τόσο τη σχετικότητα κάθε εγγράφου όσο και τη θέση του στη λίστα αποτελεσμάτων, μειώνοντας τη συνεισφορά των εγγράφων σε χαμηλότερες θέσεις μέσω λογαριθμικής απόσβεσης. Ορίζεται ως:

\begin{equation}
    \text{DCG@k} = \sum_{i=1}^{k} \frac{2^{\text{rel}_i} - 1}{\log_2(i + 1)}
    \label{eq:dcg}
\end{equation}

\begin{equation}
    \text{NDCG@k} = \frac{\text{DCG@k}}{\text{IDCG@k}}
    \label{eq:ndcg}
\end{equation}

όπου $\text{rel}_i$ αντιπροσωπεύει τη βαθμολογία σχετικότητας του εγγράφου στη θέση $i$ και $\text{IDCG@k}$ το ιδανικό DCG, που προκύπτει όταν τα σχετικά έγγραφα είναι κατατεταγμένα σε φθίνουσα σειρά σχετικότητας. Η κανονικοποίηση επιτρέπει τη σύγκριση της απόδοσης σε διαφορετικά σύνολα ερωτημάτων.

Συνολικά, ο συνδυασμός των μετρικών \textbf{Precision@k}, \textbf{Recall@k}, \textbf{F1@k}, \textbf{MRR}, \textbf{MAP} και \textbf{NDCG@k}, \textbf{Success@k} προσφέρει μια πολυδιάστατη αξιολόγηση της απόδοσης του συστήματος ανάκτησης, καλύπτοντας τόσο τη σχετικότητα όσο και τη θέση των εγγράφων στην κατάταξη — κρίσιμες παραμέτρους για την αξιολόγηση RAG συστημάτων.


\subsection{Μετρικές Αξιολόγησης Παραγωγής Κειμένου}

Το BLEU (Bilingual Evaluation Understudy) \citep{papineni2002bleu} αποτελεί μία από τις πιο ευρέως διαδεδομένες μετρικές για την αξιολόγηση αυτόματα παραγόμενου κειμένου, αναπτυχθείσα αρχικά για την αξιολόγηση μηχανικής μετάφρασης. Η θεμελιώδης ιδέα της μετρικής είναι η μέτρηση της επικάλυψης n-grams μεταξύ του υποψηφίου κειμένου που παράχθηκε αυτόματα και ενός ή περισσότερων κειμένων αναφοράς που δημιουργήθηκαν από ανθρώπους. Η μετρική υπολογίζει την ακρίβεια των n-grams διαφόρων μηκών και τα συνδυάζει χρησιμοποιώντας έναν γεωμετρικό μέσο, εφαρμόζοντας ταυτόχρονα μία ποινή συνοπτικότητας (brevity penalty) για την αποφυγή τεχνητής αύξησης της βαθμολογίας μέσω υπερβολικά σύντομων απαντήσεων. Μαθηματικά, το BLEU ορίζεται ως:

\begin{equation}
    \text{BLEU} = \text{BP} \cdot \exp\left(\sum_{n=1}^{N} w_n \log p_n\right)
\end{equation}

όπου $p_n$ αντιπροσωπεύει την ακρίβεια των n-grams μήκους $n$, υπολογιζόμενη με κομμένη μέτρηση (clipped counting) που περιορίζει την επικάλυψη στο μέγιστο πλήθος εμφανίσεων κάθε n-gram στα κείμενα αναφοράς. Συγκεκριμένα:

\begin{equation}
    p_n = \frac{\sum_{\text{n-gram} \in C} \text{Count}_{\text{clip}}(\text{n-gram})}{\sum_{\text{n-gram} \in C} \text{Count}(\text{n-gram})}
\end{equation}

Ο όρος BP (brevity penalty) εισάγει ποινή για κείμενα που είναι συντομότερα από το μήκος αναφοράς, εξασφαλίζοντας ότι η μετρική δεν επιβραβεύει τεχνητά υψηλή ακρίβεια που επιτυγχάνεται μέσω της παράλειψης πληροφορίας.

Το ROUGE (Recall-Oriented Understudy for Gisting Evaluation) \citep{lin2004rouge} αποτελεί οικογένεια μετρικών που αναπτύχθηκαν για την αξιολόγηση αυτόματων συνοπτικών περιλήψεων, εστιάζοντας στην ανάκληση παρά στην ακρίβεια. Η διάκριση αυτή είναι κρίσιμη διότι στην περίληψη κειμένου, η πληρότητα της πληροφορίας είναι συχνά πιο σημαντική από την ακρίβεια κάθε επιμέρους φράσης. Το ROUGE-N μετρά την επικάλυψη n-grams εστιάζοντας στο ποσοστό των n-grams του κειμένου αναφοράς που εμφανίζονται στο παραγόμενο κείμενο:

\begin{equation}
    \text{ROUGE-N} = \frac{\sum_{S \in \{\text{RefSum}\}} \sum_{\text{gram}_n \in S} \text{Count}_{\text{match}}(\text{gram}_n)}{\sum_{S \in \{\text{RefSum}\}} \sum_{\text{gram}_n \in S} \text{Count}(\text{gram}_n)}
\end{equation}

Μια εναλλακτική παραλλαγή, το ROUGE-L, χρησιμοποιεί την έννοια της μακρύτερης κοινής υποακολουθίας (Longest Common Subsequence, LCS), η οποία επιτρέπει την αναγνώριση δομικών ομοιοτήτων ακόμα και όταν υπάρχουν παρεμβαλλόμενες λέξεις:

\begin{equation}
    \text{ROUGE-L} = \frac{(1 + \beta^2)R_{\text{lcs}}P_{\text{lcs}}}{R_{\text{lcs}} + \beta^2P_{\text{lcs}}}
\end{equation}

όπου $R_{\text{lcs}}$ και $P_{\text{lcs}}$ αντιπροσωπεύουν την ανάκληση και την ακρίβεια βάσει της LCS αντίστοιχα, και η παράμετρος $\beta$ ελέγχει τη σχετική σημασία μεταξύ ανάκλησης και ακρίβειας.

Το BERTScore \citep{zhang2019bertscore} αντιπροσωπεύει μια σύγχρονη προσέγγιση που υπερβαίνει τους περιορισμούς των λεξικογραφικών μετρικών αξιοποιώντας contextual embeddings από προεκπαιδευμένα γλωσσικά μοντέλα για την αξιολόγηση σημασιολογικής ομοιότητας. Η θεμελιώδης διαφορά έγκειται στο ότι το BERTScore μπορεί να συλλάβει σημασιολογικές αντιστοιχίες μεταξύ φράσεων που δεν μοιράζονται κοινά tokens, αντιμετωπίζοντας έτσι φαινόμενα όπως συνωνυμία και παράφραση. Η μετρική υπολογίζει την ανάκληση, την ακρίβεια και το F1-score βασιζόμενη στη μέγιστη cosine ομοιότητα μεταξύ των embeddings των tokens:

\begin{equation}
    R_{\text{BERT}} = \frac{1}{|x|} \sum_{x_i \in x} \max_{\hat{x}_j \in \hat{x}} x_i^T \hat{x}_j
\end{equation}

\begin{equation}
    P_{\text{BERT}} = \frac{1}{|\hat{x}|} \sum_{\hat{x}_j \in \hat{x}} \max_{x_i \in x} x_i^T \hat{x}_j
\end{equation}

\begin{equation}
    F_{\text{BERT}} = 2 \cdot \frac{P_{\text{BERT}} \cdot R_{\text{BERT}}}{P_{\text{BERT}} + R_{\text{BERT}}}
\end{equation}

όπου $x$ και $\hat{x}$ αντιπροσωπεύουν τα embeddings των tokens του κειμένου αναφοράς και του υποψήφιου κειμένου αντίστοιχα.

\subsection{Εξειδικευμένες Μετρικές για Συστήματα RAG}
\label{sec:RAGAS}

Πέρα από τις παραδοσιακές μετρικές ανάκτησης και παραγωγής που αναπτύχθηκαν για ανεξάρτητα συστήματα, η ιδιαίτερη φύση των συστημάτων RAG απαιτεί εξειδικευμένες μετρικές που αξιολογούν ολιστικά τη διασύνδεση μεταξύ ανάκτησης και παραγωγής. Το πλαίσιο RAGAS (Retrieval Augmented Generation Assessment) \citep{es2023ragas} αποτελεί ένα πρωτοποριακό εργαλείο που αναπτύχθηκε ειδικά για την αυτόματη αξιολόγηση συστημάτων RAG χωρίς την απαίτηση απαντήσεων αναφοράς. Η καινοτομία της προσέγγισης έγκειται στη χρήση μεγάλων γλωσσικών μοντέλων ως κριτών (LLM-as-judge paradigm), τα οποία αξιολογούν την ποιότητα των διαφόρων συστατικών του RAG pipeline μέσω προσεκτικά σχεδιασμένων prompts.

Το πλαίσιο RAGAS θεμελιώνεται σε τρεις κεντρικές διαστάσεις ποιότητας που αποτυπώνουν διαφορετικές πτυχές της απόδοσης. Η πρώτη διάσταση αφορά τη σχετικότητα πλαισίου (Context Relevance), η οποία αξιολογεί κατά πόσον το ανακτηθέν πλαίσιο περιέχει αποκλειστικά πληροφορίες που σχετίζονται με το ερώτημα του χρήστη. Η διάσταση αυτή είναι κρίσιμη διότι η παρουσία μη σχετικής πληροφορίας όχι μόνο αυξάνει το υπολογιστικό κόστος λόγω του μεγαλύτερου πλήθους tokens που πρέπει να επεξεργαστεί το γλωσσικό μοντέλο, αλλά μπορεί επίσης να υποβαθμίσει την ποιότητα της παραγόμενης απάντησης μέσω της εισαγωγής θορύβου. Η δεύτερη διάσταση, η πιστότητα (Faithfulness), διασφαλίζει ότι οι ισχυρισμοί που διατυπώνονται στην παραγόμενη απάντηση μπορούν να εξαχθούν και να τεκμηριωθούν από το ανακτηθέν πλαίσιο. Αυτό αποτελεί θεμελιώδη απαίτηση για την αποφυγή παραισθήσεων (hallucinations), όπου το σύστημα παράγει πληροφορίες που δεν υποστηρίζονται από την παρεχόμενη τεκμηρίωση. Η τρίτη διάσταση, η σχετικότητα απάντησης (Answer Relevance), αξιολογεί κατά πόσον η παραγόμενη απάντηση αντιμετωπίζει άμεσα και πλήρως το τεθέν ερώτημα, αποφεύγοντας ασαφείς, ελλιπείς ή εκτός θέματος απαντήσεις.

Η μέτρηση της πιστότητας στο RAGAS πραγματοποιείται μέσω μιας διαδικασίας δύο σταδίων. Στο πρώτο στάδιο, το σύστημα χρησιμοποιεί ένα γλωσσικό μοντέλο για να αποσυνθέσει την παραγόμενη απάντηση σε ατομικούς, επαληθεύσιμους ισχυρισμούς. Αυτή η αποσύνθεση είναι απαραίτητη διότι οι απαντήσεις συχνά περιέχουν σύνθετες προτάσεις με πολλαπλούς ισχυρισμούς, οι οποίοι πρέπει να αξιολογηθούν ξεχωριστά. Στο δεύτερο στάδιο, για κάθε εξαχθέντα ισχυρισμό, το σύστημα επαληθεύει εάν αυτός μπορεί να συναχθεί από το ανακτηθέν πλαίσιο. Η τελική μετρική πιστότητας υπολογίζεται ως το κλάσμα των επαληθευμένων ισχυρισμών προς το σύνολο των ισχυρισμών:

\begin{equation}
    \text{Faithfulness} = \frac{|V|}{|S|}
\end{equation}

όπου $|V|$ αντιπροσωπεύει τον αριθμό των ισχυρισμών που επαληθεύονται από το πλαίσιο και $|S|$ τον συνολικό αριθμό ισχυρισμών που εξήχθησαν από την απάντηση.

Η σχετικότητα απάντησης αξιολογείται μέσω μιας έμμεσης διαδικασίας που βασίζεται στην αρχή της αμφίδρομης συνέπειας: μια καλή απάντηση θα πρέπει να είναι ικανή να οδηγήσει πίσω στο αρχικό ερώτημα. Για μια δεδομένη απάντηση, το σύστημα παράγει πολλαπλά πιθανά ερωτήματα που θα μπορούσαν λογικά να οδηγήσουν σε αυτήν την απάντηση. Στη συνέχεια, υπολογίζεται η σημασιολογική ομοιότητα μεταξύ του αρχικού ερωτήματος και κάθε παραγόμενου ερωτήματος χρησιμοποιώντας embeddings και cosine similarity. Η μέση ομοιότητα αποτελεί την τελική βαθμολογία:

\begin{equation}
    \text{Answer Relevance} = \frac{1}{n} \sum_{i=1}^{n} \cos(E_q, E_{q_i})
\end{equation}

όπου $E_q$ αντιπροσωπεύει το embedding του αρχικού ερωτήματος και $E_{q_i}$ τα embeddings των παραγόμενων ερωτημάτων. Η προσέγγιση αυτή επιτρέπει την αξιολόγηση όχι μόνο της άμεσης συνάφειας αλλά και της πληρότητας της απάντησης.

Στο πλαίσιο του AutoRAG framework \citep{kim2024autorag}, εισάγεται μια παραλλαγή της μετρικής Context Precision που λαμβάνει υπόψη τη θέση των σχετικών εγγράφων στη λίστα αποτελεσμάτων. Η μετρική αυτή υπολογίζεται ως σταθμισμένο άθροισμα της ακρίβειας σε κάθε θέση, όπου το βάρος καθορίζεται από έναν δείκτη σχετικότητας:

\begin{equation}
    \text{Context Precision@K} = \frac{\sum_{k=1}^{K} (\text{Precision@k} \times v_k)}{\text{true positives@K}}
\end{equation}

όπου $v_k \in \{0,1\}$ είναι δείκτης σχετικότητας που υποδεικνύει εάν το έγγραφο στη θέση $k$ είναι σχετικό με το ερώτημα.

\section{Το Πλαίσιο AutoRAG: Αυτοματοποιημένη Βελτιστοποίηση Συστημάτων RAG}
\label{sec:autorag}

\subsection{Αρχιτεκτονική και Φιλοσοφία Σχεδιασμού}

Το πλαίσιο AutoRAG \citep{kim2024autorag} εισάγει μια ολοκληρωμένη μεθοδολογία για την αυτοματοποιημένη βελτιστοποίηση συστημάτων RAG, μετασχηματίζοντας το πρόβλημα της επιλογής και διαμόρφωσης των επιμέρους συστατικών από μια χειροκίνητη διαδικασία σε ένα συστηματικό πρόβλημα βελτιστοποίησης παρόμοιο με τις μεθοδολογίες AutoML που έχουν αναπτυχθεί στην μηχανική μάθηση. Η κεντρική φιλοσοφική θεώρηση που διέπει το AutoRAG βασίζεται στην αρχή της αρθρωτής αποσύνθεσης, σύμφωνα με την οποία ένα σύνθετο σύστημα RAG μπορεί να αναλυθεί σε ένα σύνολο ανεξάρτητων κόμβων, ο καθένας από τους οποίους εκτελεί μια συγκεκριμένη λειτουργία και μπορεί να υλοποιηθεί με διαφορετικούς τρόπους.

Η αρχιτεκτονική του συστήματος οργανώνεται σε τρία ιεραρχικά επίπεδα αφαίρεσης που επιτρέπουν τη συστηματική εξερεύνηση του χώρου σχεδιασμού. Το πρώτο επίπεδο, το επίπεδο κόμβων, αντιπροσωπεύει τις θεμελιώδεις λειτουργίες που απαιτούνται σε ένα τυπικό RAG pipeline, όπως η επαύξηση ερωτημάτων που εμπλουτίζει ή αναδιατυπώνει το αρχικό ερώτημα του χρήστη, η ανάκτηση που εντοπίζει σχετικά έγγραφα από μια συλλογή, η επανακατάταξη που βελτιώνει τη σειρά των ανακτηθέντων εγγράφων, η επαύξηση αποσπασμάτων που εμπλουτίζει τα ανακτηθέντα αποσπάσματα με πρόσθετο πλαίσιο, η κατασκευή προτροπών που διαμορφώνει το τελικό prompt για το γλωσσικό μοντέλο, και η παραγωγή που δημιουργεί την τελική απάντηση. Το δεύτερο επίπεδο, το επίπεδο αρθρωμάτων, περιέχει συγκεκριμένες εναλλακτικές τεχνικές υλοποιήσεις για κάθε κόμβο. Για παράδειγμα, ο κόμβος ανάκτησης μπορεί να υλοποιηθεί με αλγορίθμους όπως το BM25 που βασίζεται σε λεξικογραφική αντιστοίχιση, το DPR (Dense Passage Retrieval) που χρησιμοποιεί πυκνές διανυσματικές αναπαραστάσεις, το ColBERT που συνδυάζει αποδοτικότητα με βαθιά σημασιολογική κατανόηση, ή υβριδικές προσεγγίσεις που συνδυάζουν πολλαπλές μεθόδους. Το τρίτο επίπεδο, το επίπεδο παραμέτρων, ορίζει τις υπερπαραμέτρους που ελέγχουν τη λεπτή συμπεριφορά κάθε module, όπως ο αριθμός των ανακτώμενων εγγράφων $k$, οι διαστάσεις των embeddings, οι παράμετροι των reranking μοντέλων, ή οι θερμοκρασίες παραγωγής.

Η θεμελιώδης πρόκληση που αντιμετωπίζει το AutoRAG είναι η αποδοτική εξερεύνηση του τεράστιου χώρου συνδυαστικών επιλογών. Εάν κάθε κόμβος έχει $m_i$ διαθέσιμα modules και υπάρχουν $n$ κόμβοι στο pipeline, τότε ο συνολικός αριθμός πιθανών configurations είναι $\prod_{i=1}^{n} m_i$, ο οποίος μπορεί εύκολα να φτάσει σε εκατοντάδες χιλιάδες ή εκατομμύρια συνδυασμούς. Η εξαντλητική αξιολόγηση όλων των συνδυασμών είναι υπολογιστικά ανέφικτη, ειδικά όταν η αξιολόγηση κάθε configuration απαιτεί κλήσεις σε ακριβά LLM APIs. Το AutoRAG αντιμετωπίζει αυτήν την πρόκληση μέσω μιας έξυπνης άπληστης στρατηγικής που εκμεταλλεύεται τη σειριακή δομή του RAG pipeline.

Η βασική ιδέα της greedy προσέγγισης είναι η σταδιακή κατασκευή του βέλτιστου pipeline μέσω τοπικά βέλτιστων επιλογών. Σε κάθε στάδιο, το σύστημα αξιολογεί όλα τα διαθέσιμα modules για τον τρέχοντα κόμβο, διατηρώντας σταθερές τις επιλογές που έχουν γίνει στους προηγούμενους κόμβους, και επιλέγει το module που μεγιστοποιεί την απόδοση σύμφωνα με προκαθορισμένες μετρικές. Αυτή η επιλογή στερεώνεται και το σύστημα προχωρά στον επόμενο κόμβο. Η προσέγγιση αυτή μειώνει την υπολογιστική πολυπλοκότητα από $O(\prod_{i=1}^{n} m_i)$ σε $O(\sum_{i=1}^{n} m_i)$, μια δραματική βελτίωση που καθιστά τη βελτιστοποίηση πρακτικά εφικτή.

Ωστόσο, η άπληστη προσέγγιση παρουσιάζει μια σημαντική πρόκληση: πώς αξιολογούμε modules για κόμβους όπου η απόδοση δεν είναι άμεσα μετρήσιμη; Για παράδειγμα, στον κόμβο επαύξησης ερωτημάτων, η έξοδος είναι ένα ή περισσότερα αναδιατυπωμένα ερωτήματα, για τα οποία δεν υπάρχει προφανής μετρική ποιότητας. Παρομοίως, ο κόμβος κατασκευής προτροπών παράγει ένα διαμορφωμένο prompt, το οποίο είναι δύσκολο να αξιολογηθεί ανεξάρτητα από την τελική απάντηση. Το AutoRAG επιλύει αυτό το πρόβλημα μέσω της αξιολόγησης τελικής εξόδου (downstream evaluation). Για κόμβους με δύσκολη άμεση αξιολόγηση, το σύστημα μετρά την απόδοσή τους έμμεσα, μέσω της επίδρασής τους στους επόμενους κόμβους του αγωγού. Συγκεκριμένα, για την αξιολόγηση εναλλακτικών συστατικών (modules) στον κόμβο επαύξησης ερωτημάτων, το σύστημα διατηρεί σταθερό ένα προεπιλεγμένο module για τον επόμενο κόμβο ανάκτησης, αξιολογεί την ποιότητα ανάκτησης για κάθε εναλλακτική επαύξηση ερωτήματος, και επιλέγει την επαύξηση που οδηγεί στην καλύτερη ανάκτηση.

Η στρατηγική αυτή μειώνει σημαντικά τον αριθμό των απαιτούμενων πειραμάτων. Έστω ότι ο κόμβος επαύξησης ερωτημάτων έχει $m$ εναλλακτικά modules και ο κόμβος ανάκτησης έχει $n$ εναλλακτικά. Η εξαντλητική αξιολόγηση όλων των συνδυασμών θα απαιτούσε $m \times n$ πειράματα. Η downstream evaluation προσέγγιση απαιτεί μόνο $m$ πειράματα για την αξιολόγηση του κόμβου επαύξησης (με σταθερό module ανάκτησης) και επιπλέον $n$ πειράματα για την αξιολόγηση του κόμβου ανάκτησης (με το επιλεγμένο module επαύξησης), συνολικά $m + n$ πειράματα. Αυτή η μείωση από πολλαπλασιαστική σε αθροιστική πολυπλοκότητα είναι κρίσιμη για την πρακτική εφαρμοσιμότητα του πλαισίου.

\subsection{AutoRAG-HP: Online Βελτιστοποίηση Υπερπαραμέτρων}

Η επέκταση AutoRAG-HP \citep{fu2024autorag} που παρουσιάστηκε στο συνέδριο Empirical Methods in Natural Language Processing (EMNLP) 2024 αντιμετωπίζει το συμπληρωματικό πρόβλημα της βελτιστοποίησης των υπερπαραμέτρων εντός κάθε επιλεγμένου module. Ενώ το AutoRAG επιλέγει ποια modules να χρησιμοποιήσει, το AutoRAG-HP βελτιστοποιεί πώς να διαμορφώσει αυτά τα modules για μέγιστη απόδοση. Η καινοτομία της προσέγγισης έγκειται στη διαδικτυακή (online) φύση της βελτιστοποίησης, όπου το σύστημα μαθαίνει προσαρμοστικά από την ανατροφοδότηση που λαμβάνει κατά την εκτέλεση, σε αντίθεση με τις παραδοσιακές offline μεθόδους όπως το Grid Search ή το Random Search που απαιτούν πλήρη αξιολόγηση του χώρου παραμέτρων εκ των προτέρων.

Το πρόβλημα μοντελοποιείται ως ένα πρόβλημα <<ληστή με πολλά χέρια>> (Multi-Armed Bandit, MAB), μια κλασική διατύπωση στη θεωρία online learning που προέρχεται από την αναλογία με έναν παίκτη που επιλέγει μεταξύ πολλαπλών μοχλών κουλοχέρη (slot machine) σε ένα καζίνο, προσπαθώντας να μεγιστοποιήσει τη συνολική του απόδοση. Στο πλαίσιο του AutoRAG-HP, κάθε συνδυασμός υπερπαραμέτρων αντιστοιχεί σε έναν μοχλό (arm), και η απόδοση του συστήματος με αυτόν τον συνδυασμό αποτελεί την ανταμοιβή (reward). Ο στόχος είναι η μεγιστοποίηση της αναμενόμενης αθροιστικής ανταμοιβής σε ένα χρονικό ορίζοντα:

\begin{equation}
    \max_{\theta \in \Theta} \mathbb{E}[R(\theta)] = \max_{\theta} \sum_{t=1}^{T} r_t(\theta_t)
\end{equation}

όπου $\theta$ αντιπροσωπεύει το διάνυσμα υπερπαραμέτρων που επιλέγεται σε κάθε χρονική στιγμή, $\Theta$ τον χώρο όλων των δυνατών συνδυασμών υπερπαραμέτρων, $r_t$ την ανταμοιβή που παρατηρείται στο χρόνο $t$, και $T$ τον συνολικό αριθμό επαναλήψεων. Η κεντρική πρόκληση στο MAB problem είναι η εξισορρόπηση μεταξύ εξερεύνησης (exploration), δηλαδή της δοκιμής νέων συνδυασμών για την απόκτηση πληροφορίας, και εκμετάλλευσης (exploitation), δηλαδή της χρήσης των συνδυασμών που φαίνεται να έχουν καλή απόδοση βάσει των μέχρι τώρα παρατηρήσεων.

Όταν ο χώρος υπερπαραμέτρων είναι μεγάλος, η άμεση εφαρμογή ενός MAB αλγορίθμου μπορεί να είναι αναποτελεσματική διότι ο αριθμός των χεριών (arms) γίνεται πολύ μεγάλος. Το AutoRAG-HP εισάγει μια ιεραρχική δομή που οργανώνει τον χώρο αναζήτησης σε δύο επίπεδα. Στο υψηλό επίπεδο, ένα MAB επιλέγει ποιο δομοστοιχείο (module) θα βελτιστοποιηθεί σε κάθε επανάληψη. Στο χαμηλό επίπεδο, για κάθε δομοστοιχείο υπάρχει ένα ξεχωριστό MAB που επιλέγει συγκεκριμένες τιμές για τις υπερπαραμέτρους του. Αυτή η ιεραρχική οργάνωση επιτρέπει την αποδοτική εξερεύνηση μεγάλων χώρων με πολλές διαστάσεις, διατηρώντας παράλληλα έναν εύλογο αριθμό arms σε κάθε MAB.

Η στρατηγική επιλογής βασίζεται στον αλγόριθμο <<άνω όριο εμπιστοσύνης>> (Upper Confidence Bound, UCB), ο οποίος επιλέγει arms βάσει ενός κριτηρίου που συνδυάζει την παρατηρημένη μέση απόδοση με ένα εύρος εμπιστοσύνης που αντανακλά την αβεβαιότητα. Για κάθε arm $i$ στο χρόνο $t$, το κριτήριο επιλογής είναι:

\begin{equation}
    \text{UCB}_i(t) = \bar{X}_i(t) + \sqrt{\frac{2\ln t}{n_i(t)}}
\end{equation}

όπου $\bar{X}_i(t)$ είναι η μέση παρατηρημένη ανταμοιβή του arm $i$ μέχρι το χρόνο $t$, και $n_i(t)$ ο αριθμός φορών που το arm έχει επιλεγεί. Ο πρώτος όρος ενθαρρύνει την εκμετάλλευση των arms με υψηλή παρατηρημένη απόδοση, ενώ ο δεύτερος όρος, το όριο εμπιστοσύνης (confidence bound), ενθαρρύνει την εξερεύνηση των arms που έχουν επιλεγεί λίγες φορές και συνεπώς έχουν μεγάλη αβεβαιότητα. Το εύρος εμπιστοσύνης μειώνεται με την αύξηση του $n_i(t)$, αντανακλώντας την αυξανόμενη βεβαιότητα καθώς συλλέγουμε περισσότερες παρατηρήσεις.

\subsection{Πειραματικά Αποτελέσματα και Αξιολόγηση Απόδοσης}

Η εμπειρική αξιολόγηση του AutoRAG framework διενεργήθηκε χρησιμοποιώντας το σύνολο δεδομένων ARAGOG (Advanced RAG Output Grading) \citep{eibich2024aragog}, ένα εξειδικευμένο benchmark που σχεδιάστηκε για την αξιολόγηση συστημάτων RAG στο πεδίο της Τεχνητής Νοημοσύνης και των Μεγάλων Γλωσσικών Μοντέλων. Το σύνολο δεδομένων περιλαμβάνει 423 επιστημονικά άρθρα προερχόμενα από το αρχείο arXiv, τα οποία καλύπτουν ένα ευρύ φάσμα θεμάτων από βαθιά μάθηση και επεξεργασία φυσικής γλώσσας μέχρι ενισχυτική μάθηση και υπολογιστική όραση. Επιπλέον, δημιουργήθηκαν 107 ζεύγη ερωτήσεων-απαντήσεων με τη βοήθεια του GPT-4, σχεδιασμένα να είναι τεχνικά απαιτητικά και αντιπροσωπευτικά των πραγματικών ερωτημάτων που θα υποβάλλονταν σε ένα τέτοιο σύστημα. Κάθε ζεύγος επικυρώθηκε από ανθρώπινους εμπειρογνώμονες για τη διασφάλιση της ποιότητας, της τεχνικής ακρίβειας και της συνάφειας με το περιεχόμενο της συλλογής εγγράφων.

Τα πειραματικά αποτελέσματα στο επίπεδο ανάκτησης αποκαλύπτουν σημαντικές διαφορές στην αποτελεσματικότητα διαφόρων προσεγγίσεων. Η υβριδική μέθοδος Hybrid DBSF (Dense-BM25 Score Fusion), η οποία συνδυάζει αραιές λεξικογραφικές αντιστοιχίσεις με πυκνές σημασιολογικές αναπαραστάσεις, επιτυγχάνει Context Precision@10 ίσο με 0.696 \cite{kim2024autorag}, υπερτερώντας σημαντικά του κλασικού BM25 που επιτυγχάνει 0.649. Αυτό αντιπροσωπεύει σχετική βελτίωση 7.2 τοις εκατό, επιδεικνύοντας τα οφέλη του συνδυασμού συμπληρωματικών σημάτων ανάκτησης. Ακόμη πιο εντυπωσιακή είναι η υπεροχή έναντι της αμιγούς διανυσματικής βάσης δεδομένων (VectorDB) που επιτυγχάνει μόνο 0.522, παρουσιάζοντας βελτίωση 33.3 τοις εκατό. Αυτά τα αποτελέσματα υπογραμμίζουν ότι για τεχνικά datasets με εξειδικευμένη ορολογία, η καθαρά σημασιολογική αναζήτηση μπορεί να αστοχεί στην ακριβή λεξική αντιστοίχιση που είναι απαραίτητη για την ανάκτηση σχετικών αποσπασμάτων.

Στο στάδιο της επανακατάταξης, η εισαγωγή του Flag Embedding LLM Reranker οδηγεί σε σημαντική βελτίωση της ποιότητας των τελικά επιλεγμένων εγγράφων. Η μετρική Context Precision@5, η οποία αξιολογεί την ακρίβεια των πέντε κορυφαίων ανακτηθέντων εγγράφων μετά την επανακατάταξη, αυξάνεται από 0.770 σε 0.838, μια απόλυτη βελτίωση 0.068 ή σχετική βελτίωση 8.8 τοις εκατό. Η βελτίωση αυτή είναι ιδιαίτερα σημαντική διότι τα πέντε κορυφαία έγγραφα είναι συνήθως αυτά που τελικά συμπεριλαμβάνονται στο πλαίσιο που τροφοδοτείται στο γλωσσικό μοντέλο, και επομένως η ποιότητά τους επηρεάζει άμεσα την τελική απάντηση.

Η αποδοτικότητα της βελτιστοποίησης υπερπαραμέτρων μέσω του Hierarchical MAB είναι εξίσου εντυπωσιακή. Η μετρική Recall@5, η οποία μετρά πόσο συχνά μία από τις πέντε καλύτερες διαμορφώσεις βρίσκεται μέσα στα πέντε πρώτα χέρια που επιλέγονται από τον αλγόριθμο, φτάνει περίπου το 0.8. Αυτό επιτυγχάνεται χρησιμοποιώντας μόνο περίπου το 20 τοις εκατό των κλήσεων της <<προγραμματιστικής διεπαφής μεγάλου γλωσσικού μοντέλου>> (LLM API) που απαιτεί η εξαντλητική μέθοδος της αναζήτησης πλέγματος (grid search). Η οικονομία αυτή είναι κρίσιμη στην πράξη, όπου το κόστος των API calls μπορεί να είναι σημαντικό και η χρονική καθυστέρηση της βελτιστοποίησης να αποτελεί εμπόδιο στην ταχεία ανάπτυξη συστημάτων.

Στο επίπεδο παραγωγής κειμένου, το βελτιστοποιημένο σύστημα επιτυγχάνει υψηλή ποιότητα όπως αποτιμάται από πολλαπλές μετρικές. Το G-Eval score, μια μετρική βασισμένη σε γλωσσικό μοντέλο που αξιολογεί διαστάσεις όπως η συνάφεια, η συνοχή, η ευφράδεια και η πληρότητα, φτάνει περίπου το 3.85 σε κλίμακα 1 έως 5. Επιπλέον, ο βαθμός σημασιολογικής ομοιότητας (semantic similarity score), ο οποίος μετρά τη σημασιολογική εγγύτητα μεταξύ της παραγόμενης και της αναφορικής απάντησης χρησιμοποιώντας ενσωματώσεις, επιτυγχάνει 0.919, υποδεικνύοντας ότι το σύστημα παράγει απαντήσεις που είναι σημασιολογικά πολύ κοντά στις επιθυμητές απαντήσεις παρότι μπορεί να διαφέρουν λεξικά.

Το πλαίσιο AutoRAG αντιπροσωπεύει μια ουσιαστική μεθοδολογική εξέλιξη στην κατεύθυνση της αυτοματοποίησης και βελτιστοποίησης των συστημάτων RAG. Η modular αρχιτεκτονική του, η συστηματική μεθοδολογία αξιολόγησης μέσω καθορισμένων μετρικών, και η αποδοτική greedy στρατηγική βελτιστοποίησης, συνδυάζονται για να δημιουργήσουν ένα πλαίσιο που γεφυρώνει αποτελεσματικά το χάσμα μεταξύ ερευνητικών καινοτομιών και πρακτικών εφαρμογών παραγωγής. Η δυνατότητα του συστήματος να προσαρμόζεται σε διαφορετικά domains και use cases μέσω της αυτοματοποιημένης επιλογής και διαμόρφωσης των κατάλληλων δομοστοιχείων καθιστά την ταχεία ανάπτυξη και βελτιστοποίηση RAG συστημάτων όχι μόνο εφικτή αλλά και συστηματική, μειώνοντας την εξάρτηση από επί τούτου (ad-hoc) πειραματισμό και εμπειρική γνώση.

\section{Ενσωμάτωση σε Παραγωγικά Συστήματα}
\label{sec:production_integration}

\subsection{Προκλήσεις ένταξης του RAG στην παραγωγή}

Η μετάβαση των ερευνητικών συστημάτων RAG σε παραγωγικό περιβάλλον αποκαλύπτει σημαντικές προκλήσεις που υπερβαίνουν τις θεωρητικές επιδόσεις των συστατικών μερών. Η εμπειρία από την ανάπτυξη παραγωγικών (production-ready) RAG εφαρμογών καταδεικνύει ότι η αξιοπιστία, η κλιμάκωση και η διαχείριση πόρων αποτελούν κρίσιμους παράγοντες επιτυχίας που συχνά υποτιμώνται στη φάση του πρωτοτύπου.

Η υπολογιστική πολυπλοκότητα των RAG συστημάτων εκδηλώνεται σε πολλαπλά επίπεδα της αρχιτεκτονικής. Η συνολική καθυστέρηση (latency) αποτελεί συνάρτηση όλων των επιμέρους σταδίων: της διανυσματικής αναζήτησης στη βάση γνώσης, της επανακατάταξης των ανακτηθέντων εγγράφων μέσω διασταυρωμένης κωδικοποίησης, της σύνθεσης της τελικής οδηγίας (prompt) και της παραγωγής της απάντησης από το γλωσσικό μοντέλο. Έρευνες στον τομέα της αξιολόγησης RAG συστημάτων υπογραμμίζουν τη σημασία της συνεχούς παρακολούθησης των μετρικών καθυστέρησης για τη διασφάλιση ικανοποιητικής εμπειρίας χρήστη. Συγκεκριμένα, πλαίσια αξιολόγησης όπως αυτά που προτείνονται από την κοινότητα των παραγωγικών συστημάτων τονίζουν την ανάγκη για παρακολούθηση σε πραγματικό χρόνο (real-time monitoring) του χρόνου απόκρισης σε όλα τα στάδια του pipeline.

Η κλιμάκωση των RAG συστημάτων εγείρει πρόσθετες προκλήσεις σχετικά με τη διαχείριση μνήμης και την υπολογιστική υποδομή. Οι διανυσματικές βάσεις δεδομένων απαιτούν σημαντικούς πόρους μνήμης για την αποθήκευση και την αποτελεσματική αναζήτηση εκατομμυρίων ενσωματώσεων, ενώ παράλληλα τα γλωσσικά μοντέλα επιβαρύνουν τη μνήμη της κάρτας γραφικών (GPU) κατά τη φάση της παραγωγής. Η χρήση τεχνικών όπως ο κβαντισμός των διανυσμάτων (quantization) και η εφαρμογή στρατηγικών προσωρινής αποθήκευσης (caching) μπορεί να μειώσει σημαντικά τις απαιτήσεις μνήμης, ωστόσο η ισορροπία μεταξύ απόδοσης και κατανάλωσης πόρων παραμένει κρίσιμη σχεδιαστική απόφαση.

Η αξιοπιστία και η ανθεκτικότητα σε σφάλματα (fault tolerance) αποτελούν επίσης θεμελιώδεις απαιτήσεις για παραγωγικά συστήματα. Η αποτυχία οποιουδήποτε δομοστοιχείου του RAG pipeline, είτε της βάσης διανυσμάτων, είτε του δομοστοιχείου αναδιάταξης, είτε του LLM - δεν πρέπει να οδηγεί σε ολική αποτυχία του συστήματος. Η υλοποίηση μηχανισμών ομαλής υποβάθμισης (graceful degradation), όπου το σύστημα μπορεί να επιστρέφει σε απλούστερες λειτουργίες (π.χ. άμεση παραγωγή χωρίς ανάκτηση) σε περίπτωση αποτυχίας κάποιου δομοστοιχείου, διασφαλίζει τη συνέχεια λειτουργίας. Επιπλέον, η λεπτομερής καταγραφή (logging) όλων των σταδίων επεξεργασίας και η παρακολούθηση μετρικών απόδοσης σε πραγματικό χρόνο καθίστανται απαραίτητες για την έγκαιρη ανίχνευση και αντιμετώπιση προβλημάτων.

\subsection{Η Συνεισφορά του AutoRAG σε περιβάλλοντα παραγωγής}

Το πλαίσιο AutoRAG \citep{kim2024autorag} προσφέρει συγκεκριμένες λύσεις που διευκολύνουν τη μετάβαση από την ερευνητική φάση στην παραγωγική λειτουργία. Η δυνατότητα αυτόματης ανακάλυψης του βέλτιστου pipeline επιτρέπει τη συστηματική εξερεύνηση εκατοντάδων πιθανών συνδυασμών δομοστοιχείων και παραμέτρων, μειώνοντας δραστικά τον χρόνο ανάπτυξης από εβδομάδες χειροκίνητης ρύθμισης σε λίγες ώρες αυτοματοποιημένης βελτιστοποίησης. Αυτή η συστηματική προσέγγιση διασφαλίζει επίσης την πλήρη καταγραφή και αναπαραγωγιμότητα της διαδικασίας βελτιστοποίησης, στοιχείο κρίσιμο για την τεκμηρίωση και τη μελλοντική συντήρηση του συστήματος.

Ιδιαίτερα σημαντική είναι η δυνατότητα online προσαρμογής που προσφέρει η επέκταση AutoRAG-HP \citep{fu2024autorag} μέσω των Multi-Armed Bandit (MAB) αλγορίθμων. Οι MAB αλγόριθμοι αποτελούν μία κατηγορία μεθόδων ενισχυτικής μάθησης (reinforcement learning) που αντιμετωπίζουν το πρόβλημα της ισορροπίας μεταξύ εξερεύνησης (exploration) νέων επιλογών και εκμετάλλευσης (exploitation) των γνωστών βέλτιστων επιλογών.

Η διαδικασία περιλαμβάνει τη συλλογή σημάτων ανταμοιβής από τις αλληλεπιδράσεις των χρηστών, την ενημέρωση των κατανομών πιθανότητας των MAB agents, και τη σταδιακή ανάπτυξη βελτιωμένων ρυθμίσεων μέσω A/B testing σε περιορισμένο ποσοστό της κυκλοφορίας. Το A/B testing αποτελεί πειραματική μεθοδολογία όπου δύο ή περισσότερες εκδοχές του συστήματος αναπτύσσονται ταυτόχρονα σε διαφορετικά υποσύνολα χρηστών, επιτρέποντας τη συγκριτική αξιολόγηση της απόδοσής τους υπό ρεαλιστικές συνθήκες. Όταν επιβεβαιώνεται βελτίωση που υπερβαίνει προκαθορισμένο κατώφλι, η νέα ρύθμιση προωθείται στο πλήρες παραγωγικό περιβάλλον. Αυτός ο μηχανισμός συνεχούς βελτίωσης διασφαλίζει ότι το σύστημα προσαρμόζεται δυναμικά στις μεταβαλλόμενες ανάγκες και προτιμήσεις των χρηστών.

Η αρθρωτή αρχιτεκτονική του AutoRAG εναρμονίζεται φυσικά με τις σύγχρονες πρακτικές DevOps και cloud deployment. Ο όρος DevOps αναφέρεται σε ένα σύνολο πρακτικών που ενοποιούν την ανάπτυξη λογισμικού (Development) με τις λειτουργίες πληροφορικής (Operations), επιτρέποντας τη ταχύτερη και αξιόπιστη ανάπτυξη εφαρμογών. Κάθε δομοστοιχείο του pipeline μπορεί να αντιμετωπιστεί ως ανεξάρτητη μικρουπηρεσία (microservice), μία αυτόνομη υπηρεσία που εκτελεί συγκεκριμένη λειτουργία και επικοινωνεί με άλλες υπηρεσίες μέσω καθορισμένων διεπαφών. Αυτή η προσέγγιση επιτρέπει την ανεξάρτητη κλιμάκωση, την απομόνωση αποτυχιών (fault isolation) και τη σταδιακή αναβάθμιση χωρίς διακοπή λειτουργίας (rolling updates). Η δυναμική κατανομή υπολογιστικού φορτίου ανάλογα με τις ανάγκες κάθε δομοστοιχείου, σε συνδυασμό με την υποστήριξη για containerization μέσω τεχνολογιών όπως το Kubernetes, διευκολύνει την αποδοτική διαχείριση πόρων και τη διατήρηση υψηλής διαθεσιμότητας του συστήματος. Το Kubernetes αποτελεί πλατφόρμα ορχήστρωσης (orchestration) για την αυτοματοποιημένη ανάπτυξη, κλιμάκωση και διαχείριση containerized εφαρμογών, όπου containers είναι ελαφριές, φορητές μονάδες λογισμικού που περιλαμβάνουν όλες τις απαραίτητες εξαρτήσεις για την εκτέλεση μιας εφαρμογής.

% Ερευνητικό Κενό και Συνεισφορά της Παρούσας Εργασίας

\section{Ερευνητικό Κενό και Συνεισφορά της Παρούσας Εργασίας}
\label{sec:research_gap}

\subsection{Μεθοδολογικά και Πρακτικά Εμπόδια στην Εφαρμογή Υφιστάμενων Προσεγγίσεων}

Παρά τη σημαντική πρόοδο που έχει επιτευχθεί τα τελευταία χρόνια στην ανάπτυξη και αξιολόγηση συστημάτων RAG, τα περισσότερα ερευνητικά αποτελέσματα παρουσιάζουν περιορισμένη δυνατότητα αναπαραγωγής και μεταφοράς σε εξειδικευμένα πεδία.

Πρώτον, η αναπαραγωγή των αποτελεσμάτων (replicability) παραμένει δύσκολη στην πράξη. Πολλές δημοσιευμένες εργασίες στηρίζονται σε σύνθετες πειραματικές ρυθμίσεις που είτε δεν τεκμηριώνονται επαρκώς είτε βασίζονται σε ιδιωτικά μοντέλα και μη διαθέσιμα σύνολα δεδομένων. Ως αποτέλεσμα, η επαλήθευση ή η περαιτέρω αξιολόγηση των αποτελεσμάτων καθίσταται ιδιαίτερα απαιτητική ακόμη και για ερευνητές με παρόμοια τεχνική υποδομή. Η έλλειψη τυποποιημένων αγωγών και ανοιχτών εργαλείων δυσχεραίνει επίσης τη σύγκριση μεθόδων υπό κοινά πειραματικά πρωτόκολλα.

Δεύτερον, τα περισσότερα πειραματικά δεδομένα και benchmarks παραμένουν γενικού σκοπού, όπως τα Natural Questions και MS MARCO, γεγονός που περιορίζει την προσαρμοστικότητα σε εξειδικευμένα domains. Σε τομείς όπως ο προγραμματισμός, η βιοπληροφορική ή η ιατρική, τα ερωτήματα περιλαμβάνουν εξειδικευμένη ορολογία, κώδικα ή αριθμητικές σχέσεις που δεν αποτυπώνονται σε γενικά σύνολα δεδομένων. Ως εκ τούτου, η μεταφορά των συμπερασμάτων από τα υπάρχοντα benchmarks σε πραγματικά, τεχνικά σενάρια παραμένει επισφαλής.

Τρίτον, παρότι οι μεγάλες πλατφόρμες νέφους (cloud) (π.χ. Amazon Bedrock, Google Vertex AI, Azure AI) παρέχουν υποδομές για πειραματισμό με RAG pipelines, η φύση των περισσότερων δεδομένων και η απουσία αντικειμενικών κριτηρίων καθιστούν δύσκολη την ποσοτική αξιολόγηση πέραν της χρήσης ενός LLM ως κριτή (LLM-as-judge). Αν και αυτή η προσέγγιση έχει επικρατήσει στην πρόσφατη βιβλιογραφία ως πρακτική λύση, εισάγει σημαντικούς κινδύνους μεροληψίας, καθώς η αξιολόγηση βασίζεται σε ένα μοντέλο του ίδιου τύπου με αυτό που παράγει τις απαντήσεις. Η εξάρτηση από τέτοιου είδους υποκειμενικά κριτήρια υπονομεύει τη διαφάνεια και την αξιοπιστία της έρευνας.

 Ένα επιπλέον εμπόδιο αφορά την έλλειψη έγκυρων συνόλων δεδομένων με ground truth, τόσο σε ερευνητικά όσο και σε παραγωγικά περιβάλλοντα. Ακόμη και οι οργανισμοί που αναπτύσσουν εμπορικά συστήματα RAG διαθέτουν συνήθως μόνο ακατέργαστα δεδομένα (τεκμηρίωση, άρθρα, συζητήσεις), χωρίς επισημασμένες ερωτήσεις και απαντήσεις που να επιτρέπουν αντικειμενική αξιολόγηση. Ως αποτέλεσμα, η διαδικασία αξιολόγησης βασίζεται σε συνθετικά δεδομένα που παράγονται από LLMs ή σε αυτόματη κρίση από τα ίδια τα μοντέλα (LLM-as-judge). Αυτή η εξάρτηση από συνθετικά κριτήρια εισάγει αβεβαιότητα και μεροληψία, υπονομεύοντας τη συγκρισιμότητα των αποτελεσμάτων μεταξύ διαφορετικών συστημάτων.

Η παρούσα εργασία επιχειρεί να απαντήσει σε αυτές τις προκλήσεις προτείνοντας ένα ανοιχτό, επαναχρησιμοποιήσιμο και πλήρως παραμετροποιήσιμο πλαίσιο πειραματισμού, σχεδιασμένο ώστε να ενισχύει την αναπαραγωγιμότητα, να επιτρέπει τη σύγκριση μεθόδων σε πραγματικά τεχνικά δεδομένα και να υποστηρίζει αντικειμενικές διαδικασίες αξιολόγησης πέραν της στοχαστικής κρίσης των LLMs.

Πέραν της ερευνητικής του αξίας, το προτεινόμενο πλαίσιο στοχεύει επίσης στη διευκόλυνση της πρακτικής ανάπτυξης και ενσωμάτωσης RAG pipelines, παρέχοντας κώδικα και εργαλεία που μπορούν να χρησιμοποιηθούν άμεσα σε διαφορετικά περιβάλλοντα και υποδομές. Σε αντίθεση με τις έτοιμες, συχνά κλειστές λύσεις των μεγάλων παρόχων νέφους (cloud providers), το πλαίσιο αυτό προάγει τη διαφάνεια, την ευελιξία και την επεκτασιμότητα, επιτρέποντας στους ερευνητές και μηχανικούς να δοκιμάζουν, προσαρμόζουν και αξιολογούν τα συστήματα ανάκτησης και παραγωγής με ελάχιστο κόπο ανάπτυξης.