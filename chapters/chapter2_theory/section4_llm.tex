\section{Μεγάλα Γλωσσικά Μοντέλα}
\label{section:llms}

Η εξέλιξη των μετασχηματιστών οδήγησε στη δημιουργία μιας νέας κατηγορίας μοντέλων που επαναπροσδιόρισε το τοπίο της τεχνητής νοημοσύνης: τα Μεγάλα Γλωσσικά Μοντέλα (Large Language Models, LLMs). Σε αντίθεση με την κλασική αρχιτεκτονική κωδικοποιητή-αποκωδικοποιητή των αρχικών μετασχηματιστών, τα σύγχρονα LLMs υιοθετούν αποκλειστικά την αρχιτεκτονική αποκωδικοποιητή, αποτελώντας μια στρατηγική σχεδιαστική επιλογή που αποδείχτηκε υπολογιστικά αποδοτική και εμπειρικά επιβεβαιωμένη για εργασίες παραγωγής και κατανόησης φυσικής γλώσσας \cite{xiao2025foundations}.

\subsection{Η Αρχιτεκτονική Αποκωδικοποιητή}
\label{subsection:decoder_architecture}

Τα μοντέλα αποκωδικοποιητή αποτελούν εστιασμένη αρχιτεκτονική εκδοχή της αρχικής δομής των μετασχηματιστών, διατηρώντας αποκλειστικά το τμήμα του αποκωδικοποιητή χωρίς τον κωδικοποιητή και το μηχανισμό διασταυρούμενης προσοχής. Αυτή η αρχιτεκτονική βασίζεται στη μασκαρισμένη αυτοπροσοχή, όπου κάθε λεκτική μονάδα μπορεί να αλληλεπιδρά μόνο με τις προηγούμενες λεκτικές μονάδες στην ακολουθία, εξασφαλίζοντας τη διατήρηση της αιτιακής φύσης κατά τη διάρκεια της εκπαίδευσης και της απόφασης (inference).

Η μάσκα αυτοπροσοχής για μια ακολουθία μήκους $n$ ορίζεται ως ο πίνακας $M \in \mathbb{R}^{n \times n}$:

\begin{equation}
M_{i,j} = \begin{cases}
0 & \text{αν } j \leq i \\
-\infty & \text{αν } j > i
\end{cases}
\label{eq:causal_mask}
\end{equation}

όπου ο δείκτης $i$ αντιστοιχεί στη θέση ερωτήματος (query) και ο δείκτης $j$ στη θέση κλειδιού (key). Αυτός ο πίνακας μάσκας προστίθεται στα attention scores πριν την εφαρμογή της συνάρτησης softmax, διασφαλίζοντας ότι οι μασκαρισμένες θέσεις με τιμή $-\infty$ παράγουν μηδενικές πιθανότητες προσοχής μετά τη softmax εφαρμογή, καθώς $\text{softmax}(-\infty) = 0$.

\subsubsection{Θεωρητική Τεκμηρίωση της Αρχιτεκτονικής Επιλογής}

Η επιλογή της αρχιτεκτονικής αποκωδικοποιητή στα LLMs προκύπτει από συγκλίνουσες θεωρητικές και πρακτικές εκτιμήσεις. Θεωρητικά, η γλωσσική μοντελοποίηση αποτελεί εγγενώς αυτοπαλίνδρομη διαδικασία όπου η πρόβλεψη κάθε επόμενης λεκτικής μονάδας εξαρτάται αποκλειστικά από το προηγούμενο ιστορικό, χωρίς την ανάγκη επεξεργασίας διακριτής ακολουθίας εισόδου.

Η αυτοπαλίνδρομη φύση της γλωσσικής μοντελοποίησης εκφράζεται μαθηματικά ως:
\begin{equation}
P(x_1, x_2, \ldots, x_n) = \prod_{i=1}^{n} P(x_i | x_1, x_2, \ldots, x_{i-1})
\label{eq:autoregressive}
\end{equation}
όπου κάθε λεκτική μονάδα $x_i$ προβλέπεται βάσει του προηγούμενου πλαισίου\\ $x_1, x_2, \ldots, x_{i-1}$. Αυτή η διατύπωση αποκαλύπτει την εγγενή αιτιακή φύση της γλωσσικής παραγωγής, όπου κάθε λεκτική μονάδα επηρεάζεται μόνον από τις χρονικά προγενέστερες μονάδες.

Σε αυτό το θεωρητικό πλαίσιο, η παρουσία ξεχωριστού κωδικοποιητή και διασταυρούμενης προσοχής δεν προσφέρει επιπλέον εκφραστική δύναμη, καθώς δεν υπάρχει διακριτή ακολουθία εισόδου που να απαιτεί ανεξάρτητη κωδικοποίηση. Η γλωσσική μοντελοποίηση αποτελεί εγγενώς μονοδιάστατη διαδικασία όπου κάθε νέα λεκτική μονάδα συνθέτει το υφιστάμενο πλαίσιο, δημιουργώντας μια ενιαία, συνεχώς αυξανόμενη ακολουθία \cite{xiao2025foundations}.

Από πρακτικής άποψης, η αρχιτεκτονική αποκωδικοποιητή παρουσιάζει σημαντικά πλεονεκτήματα σε όρους υπολογιστικής αποδοτικότητας και κλιμάκωσης. Η εξάλειψη του κωδικοποιητή και του μηχανισμού διασταυρούμενης προσοχής μειώνει τον αριθμό των εκπαιδεύσιμων παραμέτρων κατά περίπου το ένα τρίτο σε σχέση με τη συμβατική αρχιτεκτονική κωδικοποιητή-αποκωδικοποιητή, επιτρέποντας την ανάπτυξη μοντέλων μεγαλύτερης κλίμακας με ισοδύναμους υπολογιστικούς πόρους. Επιπλέον, η ομοιογενής αρχιτεκτονική διευκολύνει την παραλληλοποίηση των υπολογισμών κατά την εκπαίδευση, καθώς όλα τα στρώματα ακολουθούν την ίδια δομική διάταξη χωρίς εξαρτήσεις μεταξύ διαφορετικών τμημάτων του μοντέλου.

Η αποτελεσματικότητα της αρχιτεκτονικής αποκωδικοποιητή επιβεβαιώθηκε εμπειρικά μέσω των μοντέλων GPT \cite{radford2018improving, radford2019language, brown2020language}, τα οποία επέδειξαν εξαιρετικές επιδόσεις σε ευρύ φάσμα γλωσσικών εργασιών παρά τη φαινομενικά εστιασμένη αρχιτεκτονική τους. Η ικανότητα αυτών των μοντέλων να εκτελούν εργασίες κατανόησης και παραγωγής κειμένου με εξίσου υψηλή απόδοση αποκάλυψε ότι η πολυπλοκότητα της αρχιτεκτονικής κωδικοποιητή-αποκωδικοποιητή δεν αποτελεί προαπαιτούμενο για την επίτευξη γενικής γλωσσικής ικανότητας.

Η εμπειρική επιβεβαίωση των θεωρητικών πλεονεκτημάτων ενισχύθηκε περαιτέρω από τις μελέτες κλιμάκωσης που ανέδειξαν προβλέψιμους νόμους για την απόδοση των νευρωνικών δικτύων σε σχέση με την αύξηση των παραμέτρων \cite{hestness2017deep, hoffmann2022training}, επιβεβαιώνοντας ότι η αρχιτεκτονική αποκωδικοποιητή παρουσιάζει ανώτερη αποδοτικότητα στην αξιοποίηση των υπολογιστικών πόρων για την επίτευξη κλιμάκωσης.

\subsection{Μηχανισμός Πρόβλεψης και Αυτοπαλίνδρομη Παραγωγή}
\label{subsection:prediction_mechanism}

Η κατανόηση του τρόπου με τον οποίο ένα Μεγάλο Γλωσσικό Μοντέλο προβλέπει την επόμενη λεκτική μονάδα και παράγει συνεκτικό κείμενο μέσω αυτοπαλίνδρομης διαδικασίας αποτελεί κεντρικό στοιχείο για την κατανόηση της λειτουργίας των LLMs. Η διαδικασία αυτή περιλαμβάνει τη μετατροπή μιας ακολουθίας εισόδου σε κατανομή πιθανότητας επί του λεξιλογίου και τη διαδοχική εφαρμογή αυτής της διαδικασίας για την παραγωγή εκτεταμένων κειμένων.

\subsubsection{Στόχος Εκπαίδευσης και Μαθηματική Διατύπωση}

Σύμφωνα με την τυπική πρακτική, η εισαγωγή ενός γλωσσικού μοντέλου αποτελείται από μια ακολουθία λεκτικών μονάδων $\{x_0, x_1, \ldots, x_{m-1}\}$. Το γλωσσικό μοντέλο εξάγει μια κατανομή $\text{Pr}(\cdot|x_0, \ldots, x_{i-1})$ σε κάθε θέση $i$, και η λεκτική μονάδα $x_i$ επιλέγεται σύμφωνα με αυτή την κατανομή \cite{zhao2023survey}.

Το μοντέλο εκπαιδεύεται μέσω μεγιστοποίησης της λογαριθμικής πιθανοφάνειας:
\begin{equation}
\mathcal{L} = \sum_{i=1}^{m} \log \text{Pr}(x_i | x_0, \ldots, x_{i-1})
\label{eq:log_likelihood}
\end{equation}

Αυτή η στόχευση εκπαίδευσης επιτρέπει στο μοντέλο να μαθαίνει στατιστικές εξαρτήσεις μεταξύ λεκτικών μονάδων και να αναπτύσσει την ικανότητα παραγωγής συνεκτικού κειμένου.

\subsubsection{Αρχιτεκτονική Δομή και Στρώματα Μετασχηματιστή}

Η κύρια δομή του μοντέλου αποτελείται από μια στοίβα $L$ στρωμάτων μετασχηματιστή. Κάθε στρώμα περιλαμβάνει δύο υπο-στρώματα: το στρώμα αυτοπροσοχής και το Feed-Forward δίκτυο, συνδεδεμένα με υπολειματικές συνδέσεις και κανονικοποίηση στρώματος:

\begin{equation}
\text{output} = \text{LNorm}(F(\text{input}) + \text{input})
\label{eq:residual_connection}
\end{equation}

όπου $F(\cdot)$ αποτελεί τη βασική συνάρτηση του υπο-στρώματος.

\textit{Σημείωση:} Η παραπάνω μορφή αντιστοιχεί στη λεγόμενη \textbf{Post-Layer Normalization} εκδοχή του μετασχηματιστή, 
όπου η κανονικοποίηση εφαρμόζεται μετά την υπολειμματική σύνδεση. 
Σε πολλές σύγχρονες υλοποιήσεις (π.χ.~GPT-2/3), χρησιμοποιείται η εναλλακτική \textbf{Pre-Layer Normalization} μορφή, 
στην οποία η κανονικοποίηση προηγείται του υποστρώματος:
\[
\text{output} = \text{input} + F(\text{LNorm}(\text{input})).
\]
Η παραλλαγή αυτή συμβάλλει στη βελτίωση της σταθερότητας κατά την εκπαίδευση πολύ βαθιών μοντέλων.

Η αυτοπροσοχή εφαρμόζει τον μηχανισμό προσοχής QKV με ενσωματωμένη μάσκα για τη διατήρηση της αιτιακής φύσης:
\begin{equation}
\text{Attention}(\mathbf{Q}, \mathbf{K}, \mathbf{V}) = \text{Softmax}\left(\frac{\mathbf{Q}\mathbf{K}^T}{\sqrt{d_k}} + \text{Mask}\right)\mathbf{V}
\label{eq:masked_attention}
\end{equation}

όπου $\mathbf{Q}$, $\mathbf{K}
$ και $\mathbf{V} \in \mathbb{R}^{m \times d_k}$ είναι τα ερωτήματα, κλειδιά και αξίες αντίστοιχα, με $d_k$ τη διάσταση του χώρου προβολής για κάθε κεφαλή προσοχής. 

Δεδομένης αναπαράστασης $\mathbf{H}\in \mathbb{R}^{m \times d_{\text{model}}}$, η πολυκέφαλη αυτοπροσοχή επεκτείνει αυτόν τον μηχανισμό σε $h$ παράλληλους υπο-χώρους:
\begin{equation}
\text{F}(\mathbf{H}) = \text{Concat}(\text{head}_1, \ldots, \text{head}_h)\mathbf{W}^{head}
\label{eq:multihead}
\end{equation}

όπου κάθε κεφαλή $\text{head}_j$ υπολογίζεται ως:
\begin{equation}
\text{head}_j = \text{Attention}(\mathbf{H}\mathbf{W}_j^Q, \mathbf{H}\mathbf{W}_j^K, \mathbf{H}\mathbf{W}_j^V)
\label{eq:attention_head}
\end{equation}

με $\mathbf{W}_j^Q$, $\mathbf{W}_j^K$, $\mathbf{W}_j^V \in \mathbb{R}^{d_{\text{model}} \times d_k}$ τους πίνακες προβολής, όπου $d_k = d_{\text{model}}/h$ και $h$ ο αριθμός των κεφαλών προσοχής.

Μετά την επεξεργασία από τα $L$ στρώματα μετασχηματιστή, η τελική πρόβλεψη πραγματοποιείται μέσω γραμμικού μετασχηματισμού και εφαρμογής softmax:
\begin{equation}
\mathbf{P} = \text{Softmax}(\mathbf{H}^L \mathbf{W}^o)
\label{eq:output_layer}
\end{equation}

όπου $\mathbf{H}^L \in \mathbb{R}^{m \times d_{\text{model}}}$ είναι η έξοδος του τελευταίου στρώματος, $\mathbf{W}^o \in \mathbb{R}^{d_{\text{model}} \times |V|}$ ο πίνακας παραμέτρων εξόδου, και $|V|$ το μέγεθος του λεξιλογίου. Το αποτέλεσμα $\mathbf{P} \in \mathbb{R}^{m \times |V|}$ περιέχει κατανομές πιθανότητας για κάθε θέση στην ακολουθία.

Η παραγωγή κειμένου υλοποιείται μέσω αυτοπαλίνδρομης και επαναληπτικής εφαρμογής της διαδικασίας πρόβλεψης. Δεδομένης αρχικής ακολουθίας (prompt), το μοντέλο εκτελεί τα εξής βήματα μέχρι την επίτευξη κριτηρίου τερματισμού:

1. Υπολογισμός κατανομής πιθανότητας για το επόμενο token βάσει του τρέχοντος πλαισίου
2. Επιλογή token μέσω στρατηγικής δειγματοληψίας από την παραγόμενη κατανομή
3. Επέκταση της ακολουθίας με το νέο token και ενημέρωση του πλαισίου
4. Επανάληψη της διαδικασίας με το επικαιροποιημένο πλαίσιο

\subsubsection{Στρατηγικές Δειγματοληψίας και Επίδραση στην Ποιότητα}

Η επιλογή στρατηγικής δειγματοληψίας επηρεάζει καθοριστικά τη ποιότητα, συνοχή και ποικιλομορφία του παραγόμενου κειμένου \cite{zhao2023survey}:\begin{itemize}
    \item \textbf{Greedy Decoding:} Επιλογή της λεκτικής μονάδας με τη μέγιστη πιθανότητα, παρέχοντας ντετερμινιστικά αποτελέσματα με υψηλή τοπική συνοχή αλλά περιορισμένη γλωσσική ποικιλομορφία.
    \item \textbf{Temperature Sampling:} Τροποποίηση της κατανομής πιθανότητας με παράμετρο θερμοκρασίας $\tau$:
\begin{equation}
P_{\tau}(x_i | \text{context}) = \frac{\exp(\text{logit}_i / \tau)}{\sum_j \exp(\text{logit}_j / \tau)}
\label{eq:temperature}
\end{equation}
όπου χαμηλότερες τιμές $\tau < 1$ οδηγούν σε πιο συντηρητικές και προβλέψιμες επιλογές με ενισχυμένη τοπική συνοχή, ενώ υψηλότερες τιμές $\tau > 1$ αυξάνουν τη στοχαστικότητα και τη δημιουργικότητα του παραγόμενου κειμένου.
    \item \textbf{Nucleus Sampling (Top-p):} Δειγματοληψία από το ελάχιστο σύνολο λεκτικών μονάδων με αθροιστική πιθανότητα που υπερβαίνει το κατώφλι $p$, εξισορροπώντας αποδοτικά την ποιότητα και ποικιλομορφία του παραγόμενου κειμένου διατηρώντας παράλληλα τη σημασιολογική συνοχή.
\end{itemize}
Αυτός ο ολοκληρωμένος μηχανισμός επιτρέπει στα LLMs να παράγουν συνεκτικό κείμενο που διατηρεί γλωσσική και σημασιολογική συνοχή σε εκτεταμένες ακολουθίες, αποτελώντας τη βάση για την ευρεία εφαρμογή τους σε εργασίες παραγωγής και επεξεργασίας φυσικής γλώσσας \cite{xiao2025foundations}.
\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{images/chapter2/llm.png}
    \caption{Απεικόνιση της διαδικασίας πρόβλεψης σε ένα Μεγάλο Γλωσσικό Μοντέλο (LLM). 
Οι ενσωματώσεις εισόδου (token + positional encodings) περνούν από μια στοίβα $L$ στρωμάτων μετασχηματιστή 
με αυτοπροσοχή, κανονικοποίηση και Feed-Forward δίκτυα, ώστε να παραχθεί η κρυφή αναπαράσταση $h_t$ για τη θέση $t$. 
Η αναπαράσταση αυτή ενσωματώνει πληροφορία από όλο το προηγούμενο πλαίσιο και τροφοδοτεί τον γραμμικό μετασχηματισμό 
και τη συνάρτηση softmax, με αποτέλεσμα την κατανομή πιθανοτήτων στο λεξιλόγιο. 
Τέλος, μέσω δειγματοληψίας, επιλέγεται το επόμενο token εξόδου.}

    \label{fig:llm}
\end{figure}

\subsection{Εκπαίδευση Μεγάλων Γλωσσικών Μοντέλων}
\label{subsection:llm_training}

Η εκπαίδευση ενός Μεγάλου Γλωσσικού Μοντέλου (LLM) βασίζεται στη μεγιστοποίηση της πιθανοφάνειας 
σε μεγάλα σύνολα δεδομένων κειμένου. Έστω ένα σύνολο εκπαίδευσης $D$ που αποτελείται από $K$ ακολουθίες. 
Για κάθε ακολουθία $x = (x_0, x_1, \ldots, x_m) \in D$, η λογαριθμική πιθανοφάνεια ορίζεται ως:

\begin{equation}
\mathcal{L}_{\theta}(x) = \sum_{i=1}^{m} \log \Pr_{\theta}(x_i \mid x_0, \ldots, x_{i-1})
\label{eq:llm_loglikelihood}
\end{equation}

όπου το $\theta$ δηλώνει τις παραμέτρους του μοντέλου. Ο στόχος της εκπαίδευσης είναι η εκτίμηση των παραμέτρων $\theta$ 
μέσω της μεγιστοποίησης της συνολικής πιθανοφάνειας όλων των ακολουθιών εκπαίδευσης:

\begin{equation}
\hat{\theta} = \arg \max_{\theta} \sum_{x \in D} \mathcal{L}_{\theta}(x)
\label{eq:llm_mle}
\end{equation}

Η βελτιστοποίηση του αντικειμενικού σκοπού υλοποιείται με παραλλαγές του αλγορίθμου \textbf{επικλινής καθόδου}, 
οι οποίες υποστηρίζονται από σύγχρονες βιβλιοθήκες βαθιάς μάθησης. Ωστόσο, καθώς τα μοντέλα αυξάνονται 
σε μέγεθος και πολυπλοκότητα, αναδύονται σοβαρές προκλήσεις κλιμάκωσης.

Από πρακτική σκοπιά, η εκπαίδευση LLMs με δεκάδες ή εκατοντάδες δισεκατομμύρια παραμέτρους 
απαιτεί χιλιάδες ώρες επεξεργασίας σε κατανεμημένα υπερυπολογιστικά clusters \cite{brown2020language, narayanan2021efficient}. 
Τέτοια περιβάλλοντα είναι επιρρεπή σε σφάλματα: μία μεμονωμένη πτώση κόμβου ή αστοχία 
δικτύου μπορεί να οδηγήσει στην αποτυχία ολόκληρης της εκπαιδευτικής διαδικασίας, 
καθιστώντας απαραίτητη την υλοποίηση μηχανισμών ανοχής σε σφάλματα (\textit{fault tolerance}) 
και περιοδικής αποθήκευσης κατάστασης (\textit{checkpointing}) \cite{rajbhandari2020zero, shoeybi2019megatron}. 
Παράλληλα, η επικοινωνία μεταξύ κόμβων, ιδιαίτερα για τον συγχρονισμό παραμέτρων στο πλαίσιο της 
παράλληλης εκπαίδευσης δεδομένων ή της παράλληλης εκπαίδευσης μοντέλου, δημιουργεί σημαντικά 
επικοινωνιακά σημεία συμφόρησης \cite{goyal2017accurate, narayanan2021efficient}. 
Η ανισορροπία στην απόδοση των κόμβων (\textit{stragglers}) μπορεί να μειώσει δραστικά την αποδοτικότητα του cluster. 

Επιπλέον, η κατανάλωση ενέργειας και το οικονομικό κόστος σε τέτοια συστήματα είναι τεράστια, 
καθιστώντας την εκπαίδευση απαγορευτική για μικρότερους οργανισμούς \cite{patterson2021carbon, sharir2020cost}. 
Από αλγοριθμική σκοπιά, η εκπαίδευση βαθιών και πολύ μεγάλων νευρωνικών δικτύων ενέχει κινδύνους αστάθειας στη βελτιστοποίηση, 
απαιτώντας προσαρμογές στην αρχιτεκτονική (π.χ. κανονικοποίηση στρώματος, υπολειμματικές συνδέσεις, 
προσαρμοστικούς χρονοπρογραμματιστές ρυθμού μάθησης) για να εξασφαλιστεί η σύγκλιση \cite{ba2016layer, he2016deep}. 

Παρά τις προκλήσεις αυτές, η κλιμάκωση των LLMs έχει οδηγήσει σε σταθερές βελτιώσεις απόδοσης, 
όπως περιγράφουν οι νόμοι κλιμάκωσης \cite{kaplan2020scaling, hoffmann2022training}, 
προσφέροντας ισχυρό κίνητρο για την ανάπτυξη όλο και μεγαλύτερων μοντέλων.
\subsection{Προσαρμογή}
\label{subsection:finetuning}

Η προεκπαίδευση (pretraining) ενός Μεγάλου Γλωσσικού Μοντέλου (LLM) παρέχει γενικευμένες 
γλωσσικές ικανότητες που αποδεικνύονται χρήσιμες σε ένα ευρύ φάσμα εφαρμογών. Ωστόσο, 
η απόδοση του μοντέλου σε εξειδικευμένα καθήκοντα ή τομείς συχνά απαιτεί προσαρμογή (fine-tuning) \cite{howard2018universal, devlin2019bert}. 
Η βασική ιδέα συνίσταται στην εκπαίδευση του προεκπαιδευμένου μοντέλου σε μικρότερα, 
εξειδικευμένα σύνολα δεδομένων, με στόχο τη βελτίωση της γενίκευσης σε συγκεκριμένους τομείς.

Οι κύριες προσεγγίσεις περιλαμβάνουν:
\begin{itemize}
    \item \textbf{Πλήρης προσαρμογή (full fine-tuning):} ενημέρωση όλων των παραμέτρων του 
    μοντέλου. Παρά την υψηλή αποτελεσματικότητα, η μέθοδος αυτή είναι υπολογιστικά δαπανηρή 
    και δύσκολα εφαρμόσιμη σε LLMs δισεκατομμυρίων παραμέτρων.
    \item \textbf{Αποδοτική προσαρμογή παραμέτρων} (\textit{parameter-efficient tuning}): 
    τεχνικές όπως οι \textit{προσαρμογείς} (adapters), η \textit{προρρυθμισμένη προσαρμογή προθέματος} 
    (prefix tuning) και η μέθοδος \textit{χαμηλόβαθμης προσαρμογής} (LoRA, \textit{Low-Rank Adaptation}) 
    \cite{hu2021lora}, όπου προσαρμόζεται μόνο ένα μικρό υποσύνολο παραμέτρων, 
    επιτυγχάνοντας σημαντική μείωση των απαιτήσεων σε μνήμη και υπολογιστική ισχύ.
    \item \textbf{Εκπαίδευση με οδηγίες και ενίσχυση από ανθρώπινη ανατροφοδότηση:} 
    \textit{instruction tuning} και \textit{reinforcement learning from human feedback (RLHF)}, 
    τα οποία στοχεύουν στην ευθυγράμμιση του μοντέλου με ανθρώπινες προτιμήσεις και κοινωνικές 
    προσδοκίες \cite{ouyang2022training}.
\end{itemize}

Η διαδικασία fine-tuning έχει καθιερωθεί ως ισχυρό εργαλείο για την προσαρμογή των LLMs σε 
εξειδικευμένα περιβάλλοντα. Ωστόσο, παραμένει περιορισμένη από τη θεμελιώδη στατικότητα των 
παραμέτρων του μοντέλου: η γνώση που ενσωματώνεται κατά την προεκπαίδευση και προσαρμογή 
δεν μπορεί να επικαιροποιηθεί δυναμικά. Η αναγκαιότητα πρόσβασης σε εξωτερική, επίκαιρη 
και αξιόπιστη γνώση καθιστά αναγκαία την ανάπτυξη συμπληρωματικών προσεγγίσεων. 
Στη συνέχεια εξετάζεται διεξοδικά η \textbf{Επαυξημένη Παραγωγή μέσω Ανάκτησης
(Retrieval-Augmented Generation, RAG)}, μία τεχνική που συνδυάζει την υπολογιστική ισχύ των 
LLMs με την αξιοποίηση εξωτερικών γνωσιακών βάσεων, παρέχοντας ένα δυναμικό και 
επεκτάσιμο πλαίσιο για την υπέρβαση των περιορισμών της στατικής εκπαίδευσης.
