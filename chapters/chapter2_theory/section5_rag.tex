\section{Επαυξημένη Παραγωγή μέσω Ανάκτησης}
\label{subsection:rag}

Παρά την εντυπωσιακή τους ισχύ, τα Μεγάλα Γλωσσικά Μοντέλα (LLMs) παραμένουν εγγενώς 
περιορισμένα από τη στατικότητα των παραμέτρων τους: η γνώση που κατέχουν αντανακλά 
αποκλειστικά το σύνολο εκπαίδευσης και τη χρονική στιγμή κατά την οποία αυτό συλλέχθηκε. 
Αυτό δημιουργεί σοβαρά προβλήματα σε εφαρμογές που απαιτούν πρόσβαση σε επικαιροποιημένη 
πληροφορία ή σε εξειδικευμένη γνώση που δεν περιλαμβάνεται στο αρχικό corpus. 

Ένα επιπλέον ζήτημα είναι το φαινόμενο της \textbf{παραισθητικότητας} (\textit{hallucination}), 
όπου το μοντέλο παράγει συντακτικά ορθό και πειστικό κείμενο το οποίο όμως δεν έχει 
αντικειμενική αντιστοίχιση με τα δεδομένα ή την πραγματικότητα \cite{ji2023survey}. 
Οι παραισθήσεις μπορεί να προκύψουν λόγω έλλειψης σχετικής πληροφορίας, 
στατιστικής μεροληψίας στο σύνολο εκπαίδευσης, ή λόγω της φύσης των αυτοπαλίνδρομων 
μηχανισμών πρόβλεψης που στοχεύουν στη γλωσσική συνοχή αλλά όχι απαραίτητα στην 
πραγματολογική ακρίβεια. Αυτό περιορίζει σοβαρά την αξιοπιστία των LLMs σε 
ευαίσθητες εφαρμογές (π.χ. ιατρική πληροφόρηση, νομικά κείμενα, επιστημονικές αναφορές). 

Η τεχνική της \textbf{Επαυξημένης Παραγωγής μέσω Ανάκτησης} (\textit{Retrieval-Augmented Generation, RAG}) 
προτείνει μια υβριδική προσέγγιση: συνδυάζει τις δυνατότητες γενίκευσης και κατανόησης των LLMs 
με τη δυναμική ανάκτηση πληροφοριών από εξωτερικές βάσεις γνώσης. Με αυτό τον τρόπο, 
το μοντέλο δεν περιορίζεται στις παραμέτρους του, αλλά μπορεί να ενισχύσει την παραγωγή κειμένου 
με επίκαιρες, σχετικές και αξιόπιστες πηγές \cite{lewis2020rag, shuster2021retrieval}. 
Η RAG έχει αναδειχθεί ως κρίσιμη μεθοδολογία για την ενίσχυση της ακρίβειας, 
τη μείωση φαινομένων παραισθήσεων και την αύξηση της επεξηγησιμότητας των αποτελεσμάτων.
\subsection{Αρχιτεκτονική του RAG}
\label{subsection:rag_architecture}

Η βασική αρχιτεκτονική της Επαυξημένης Παραγωγής μέσω Ανάκτησης (RAG) συνδυάζει δύο 
διακριτά υποσυστήματα: τον \textit{Ανακτητή} (Retriever) και τον \textit{Γεννήτορα} (Generator). 
Ο Ανακτητής έχει ως ρόλο την αναζήτηση σχετικών εγγράφων ή αποσπασμάτων από μια 
εξωτερική βάση γνώσης $C$, με βάση το ερώτημα $q$ που παρέχεται στο σύστημα. 
Στη συνέχεια, ο Γεννήτορας (συνήθως ένα LLM αρχιτεκτονικής αποκωδικοποιητή) 
λαμβάνει ως είσοδο τον συνδυασμό του ερωτήματος με τα ανακτημένα τεκμήρια, 
παράγοντας την τελική απάντηση \cite{lewis2020rag, izacard2021leveraging}.

Τυπικά, η διαδικασία μπορεί να περιγραφεί ως εξής. Για κάθε ερώτημα $q$, 
ο Ανακτητής υπολογίζει μια πιθανότητα $p(d|q)$ για κάθε τεκμήριο $d \in C$. 
Η πιθανότητα παραγωγής μιας απάντησης $y$ δίνεται από τον Γεννήτορα ως:

\begin{equation}
P(y \mid q) = \sum_{d \in C} P(y \mid q, d) \, p(d \mid q)
\label{eq:rag}
\end{equation}

όπου $P(y \mid q, d)$ είναι η πιθανότητα να παραχθεί η απάντηση $y$ 
δεδομένου του ερωτήματος $q$ και του τεκμηρίου $d$, και $p(d|q)$ 
είναι η κατανομή πιθανοτήτων που αποδίδει ο Ανακτητής στο σύνολο 
των εγγράφων. Η εξίσωση αυτή αποτυπώνει την αρχή του RAG: 
η τελική γενεσιουργία δεν εξαρτάται αποκλειστικά από τις παραμέτρους 
του LLM, αλλά ενισχύεται από την πληροφορία που ανακτάται δυναμικά.

Ο Ανακτητής μπορεί να υλοποιηθεί είτε με \textbf{αραιές αναπαραστάσεις} 
(sparse retrievers) όπως το BM25 \cite{robertson2009probabilistic}, 
είτε με \textbf{πυκνές αναπαραστάσεις} (dense retrievers) που βασίζονται 
σε ενσωματώσεις μέσω νευρωνικών δικτύων \cite{karpukhin2020dense}. 
Σε πρακτικές εφαρμογές συχνά χρησιμοποιούνται υβριδικές μέθοδοι που 
συνδυάζουν τα πλεονεκτήματα και των δύο \cite{sawarkar2024blended}. 
Ο Γεννήτορας είναι συνήθως ένα LLM τύπου Transformer αποκωδικοποιητή, 
εκπαιδευμένο για αυτοπαλίνδρομη παραγωγή κειμένου, με δυνατότητα 
να ενσωματώνει τα ανακτημένα αποσπάσματα ως επιπρόσθετο context.


\subsection{Βάσεις Δεδομένων Διανυσμάτων (Vector Databases)}
\label{subsection:vector_db}

Η επιτυχία των συστημάτων RAG εξαρτάται σε μεγάλο βαθμό από την ικανότητα 
αποθήκευσης και αποδοτικής αναζήτησης μεγάλου όγκου ενσωματώσεων (embeddings). 
Κάθε τεκμήριο κειμένου $d \in C$ χαρτογραφείται σε ένα διάνυσμα υψηλής διάστασης 
μέσω ενός προεκπαιδευμένου μοντέλου ενσωμάτωσης. Η αναζήτηση της σχετικότητας 
μεταξύ ερωτήματος και τεκμηρίων ανάγεται έτσι σε πρόβλημα υπολογισμού ομοιότητας 
διανυσμάτων σε χώρους με εκατοντάδες διαστάσεις.

Η πιο διαδεδομένη μετρική σε τέτοιες βάσεις είναι η \textbf{ομοιότητα συνημιτόνου} 
(\textit{cosine similarity}). Δοθέντων δύο διανυσμάτων 
$\mathbf{u}, \mathbf{v} \in \mathbb{R}^d$, η ομοιότητα συνημιτόνου ορίζεται ως:

\begin{equation}
\text{sim}_{\cos}(\mathbf{u}, \mathbf{v}) = 
\frac{\mathbf{u} \cdot \mathbf{v}}{\|\mathbf{u}\|\|\mathbf{v}\|}.
\label{eq:cosine_similarity}
\end{equation}

Η τιμή της $\text{sim}_{\cos}$ κυμαίνεται στο $[-1,1]$, με την τιμή $1$ να υποδηλώνει 
ταυτόσημη κατεύθυνση, $0$ ορθογωνιότητα και $-1$ αντίθετη κατεύθυνση. Στην πράξη 
χρησιμοποιείται συχνά η \textbf{απόσταση συνημιτόνου}:

\begin{equation}
\text{dist}_{\cos}(\mathbf{u}, \mathbf{v}) = 1 - \text{sim}_{\cos}(\mathbf{u}, \mathbf{v}),
\end{equation}

ώστε να εκφράζεται η εγγύτητα ως θετική μετρική. Εφόσον τα embeddings 
κανονικοποιούνται σε μοναδιαίο μήκος ($\|\mathbf{u}\|=\|\mathbf{v}\|=1$), η 
ομοιότητα ισοδυναμεί με το εσωτερικό γινόμενο $\mathbf{u} \cdot \mathbf{v}$, 
καθιστώντας τον υπολογισμό αποδοτικό και εύκολα υλοποιήσιμο σε κλίμακα 
\cite{singhal2001modern}.

Για την αποδοτική διαχείριση τέτοιων συλλογών χρησιμοποιούνται 
\textbf{βάσεις δεδομένων διανυσμάτων} (vector databases), όπως FAISS, 
Milvus και Qdrant. Οι βάσεις αυτές υλοποιούν 
δομές δεικτοδότησης και αλγορίθμους προσεγγιστικής εύρεσης πλησιέστερου γείτονα \textit{approximate nearest neighbor search (ANN)}, 
που μειώνουν δραστικά την πολυπλοκότητα αναζήτησης σε σχέση με την εξαντλητική 
αναζήτηση, επιτρέποντας την ταχεία ανάκτηση ακόμα και σε συλλογές δισεκατομμυρίων 
τεκμηρίων. Επιπλέον, οι σύγχρονες βάσεις υποστηρίζουν υβριδικούς δείκτες που 
συνδυάζουν πυκνές και αραιές αναπαραστάσεις, καθιστώντας δυνατή την ταυτόχρονη 
αξιοποίηση σημασιολογικής και λεκτικής πληροφορίας \cite{sawarkar2024blended}.
\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{images/chapter2/RAG.drawio.png}
    \caption{Αρχιτεκτονική ροή ενός συστήματος Επαυξημένης Παραγωγής μέσω Ανάκτησης (RAG). 
Η διαδικασία περιλαμβάνει δύο διακριτά στάδια: (\textit{i}) τη \textbf{δεικτοδότηση}, 
όπου τα έγγραφα τεμαχίζονται, μετατρέπονται σε διανύσματα μέσω μοντέλου ενσωματώσεων 
και αποθηκεύονται σε διανυσματική βάση δεδομένων, και (\textit{ii}) την \textbf{online 
ανάκτηση και παραγωγή}, όπου το ερώτημα του χρήστη ενσωματώνεται, αναζητά σχετικές 
εγγραφές στη βάση και, σε συνδυασμό με τις οδηγίες (prompt), τροφοδοτεί το LLM για 
την παραγωγή της τελικής απάντησης.}
    \label{fig:RAG}
\end{figure}
\subsection{Προκλήσεις και Υπερπαράμετροι στα Συστήματα RAG}
\label{subsection:rag_hyperparams}

Παρότι τα συστήματα RAG βελτιώνουν σημαντικά την ακρίβεια και μειώνουν τις 
παραισθήσεις, η απόδοσή τους εξαρτάται έντονα από μια σειρά υπερπαραμέτρων και 
σχεδιαστικών επιλογών. Οι σημαντικότερες προκλήσεις συνοψίζονται παρακάτω:

\begin{itemize}
    \item \textbf{Τμηματοποίηση τεκμηρίων (chunking):} Τα κείμενα διασπώνται σε τμήματα 
    (\textit{chunks}) τα οποία μετατρέπονται σε ενσωμάτωση. Το μέγεθος του chunk ($l_{chunk}$) 
    επηρεάζει άμεσα την ισορροπία ανάμεσα στη λεπτομέρεια και στη σημασιολογική 
    πληρότητα. Πολύ μικρά chunks οδηγούν σε απώλεια συμφραζομένων, ενώ πολύ μεγάλα 
    chunks αυξάνουν τον θόρυβο και το κόστος \cite{gao2022precise}.
    
    \item \textbf{Αριθμός ανακτώμενων τεκμηρίων (top-$k$):} Ο Ανακτητής 
    επιστρέφει τα $k$ πιο σχετικά τεκμήρια. Η επιλογή του $k$ επηρεάζει την 
    απόδοση: μικρό $k$ μπορεί να οδηγήσει σε απώλεια κρίσιμης πληροφορίας, 
    ενώ πολύ μεγάλο $k$ αυξάνει την καθυστέρηση και εισάγει θόρυβο από άσχετα έγγραφα 
    \cite{fu2024autorag}.
    
    \item \textbf{Ποιότητα Ανακτητή:} Η επιλογή ανάμεσα σε αραιούς, πυκνούς ή 
    υβριδικούς ανακτητές καθορίζει τη σχετικότητα των αποτελεσμάτων. Πυκνοί 
    ανακτητές (π.χ. DPR) αποδίδουν καλύτερα σημασιολογικά, αλλά έχουν υψηλότερο 
    κόστος εκπαίδευσης και συντήρησης \cite{karpukhin2020dense}.
    
    \item \textbf{Συγχώνευση και επαναβαθμολόγηση (fusion, reranking):} 
    Προηγμένες μέθοδοι όπως το \textit{reciprocal rank fusion} ή rerankers 
    βασισμένοι σε γλωσσικά μοντέλα (π.χ. MonoT5, ColBERT) βελτιώνουν την ακρίβεια 
    αλλά αυξάνουν το υπολογιστικό φορτίο \cite{khattab2020colbert, nogueira2020monot5}.
\end{itemize}
Συμπερασματικά, η Επαυξημένη Παραγωγή μέσω Ανάκτησης (RAG) συνιστά μια μεθοδολογική 
καινοτομία που επιτρέπει στα LLMs να υπερβούν τον περιορισμό της στατικής γνώσης, 
μέσω της δυναμικής ενσωμάτωσης εξωτερικών τεκμηρίων. Παρά τα σημαντικά της πλεονεκτήματα, 
η απόδοση της προσέγγισης παραμένει ιδιαίτερα ευαίσθητη σε κρίσιμες υπερπαραμέτρους 
και σχεδιαστικές επιλογές, όπως η στρατηγική διάσπασης τεκμηρίων, το μέγεθος του top-$k$ 
κατά την ανάκτηση και η ποιότητα των αλγορίθμων επαναβαθμολόγησης. Οι παράγοντες αυτοί 
αναδεικνύουν την ανάγκη για συστηματική μελέτη και μεθοδολογίες βελτιστοποίησης που 
να μπορούν να ανταποκριθούν στις απαιτήσεις εφαρμογών μεγάλης κλίμακας.

Το επόμενο κεφάλαιο επικεντρώνεται στις υφιστάμενες \textbf{ερευνητικές προκλήσεις} που 
αφορούν την αξιολόγηση, τη βελτιστοποίηση και την κλιμάκωση συστημάτων RAG. 
Η ανάλυση αυτή αποσκοπεί στην ανάδειξη των περιορισμών των τρεχουσών προσεγγίσεων 
και στην τεκμηρίωση των ανοιχτών ζητημάτων που χρήζουν περαιτέρω διερεύνησης. 