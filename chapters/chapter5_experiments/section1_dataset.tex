\section{Σύνολο Δεδομένων και Τομέας Εφαρμογής}
\label{section:dataset}

Ένα από τα χαρακτηριστικά της παρούσας εργασίας αφορά την επιλογή 
του συνόλου δεδομένων για την αξιολόγηση του προτεινόμενου συστήματος. Αντί 
της υιοθέτησης κάποιου από τα κλασικά συνθετικά μετροπρογράμματα (benchmarks) 
που χρησιμοποιούνται συνήθως για την αξιολόγηση συστημάτων RAG, όπως τα 
MS MARCO \cite{bajaj2016ms}, Natural Questions \cite{kwiatkowski2019natural}, 
ή HotpotQA \cite{yang2018hotpotqa}, επιλέχθηκε η αξιολόγηση σε πραγματικά 
δεδομένα από τον τομέα της τεχνολογίας λογισμικού. Η επιλογή αυτή 
υπαγορεύθηκε από τη στόχευση να αξιολογηθεί η ικανότητα του συστήματος να 
λειτουργεί αποτελεσματικά σε πραγματικές συνθήκες εφαρμογής, όπου τα 
δεδομένα παρουσιάζουν υψηλό βαθμό τεχνικότητας, εξειδίκευσης και δομικής 
πολυπλοκότητας.

\subsection{Προέλευση και Χαρακτηριστικά Δεδομένων}
\label{subsection:dataset_origin}

Το σύνολο δεδομένων προέρχεται από την πρόσφατη εργασία του Θεμιστοκλή Διαμαντόπουλου και του Ανδρέα Συμεωνίδη \cite{diamantopoulos2025directory}, η οποία δημιούργησε έναν 
συστηματικό κατάλογο (directory) με τα papers και τα αντίστοιχα datasets 
που παρουσιάστηκαν στο data track του συνεδρίου Mining Software Repositories 
(MSR) κατά τα τελευταία δώδεκα έτη. Το MSR conference αποτελεί ένα από τα 
κορυφαία διεθνή συνέδρια στον τομέα της εμπειρικής τεχνολογίας λογισμικού, 
με έμφαση στην εξόρυξη και ανάλυση δεδομένων από αποθετήρια κώδικα, συστήματα 
παρακολούθησης σφαλμάτων (bug trackers), και άλλες πηγές που σχετίζονται με 
την ανάπτυξη λογισμικού.
Ο κατάλογος περιλαμβάνει μεταδεδομένα και πληροφορίες αναφοράς για όλα τα 
papers των data tracks, καθώς και χαρακτηρισμό των datasets σύμφωνα με την 
πηγή δεδομένων και την συμμόρφωσή τους με τις αρχές FAIR (Findable, 
Accessible, Interoperable, Reusable). Τα datasets που συλλέχθηκαν 
κατηγοριοποιούνται σε διάφορους τύπους, συμπεριλαμβανομένων:

\begin{itemize}
    \item \textbf{Αποθετήρια κώδικα (Code Repositories):} Δεδομένα από 
    πλατφόρμες όπως GitHub, GitLab, ή Bitbucket, περιλαμβάνοντα ιστορικό 
    commits, pull requests, και code reviews.
    
    \item \textbf{Συστήματα παρακολούθησης ζητημάτων (Issue Tracking):} 
    Αναφορές σφαλμάτων, αιτήματα χαρακτηριστικών, και τεχνικές συζητήσεις 
    από συστήματα όπως Jira, Bugzilla, ή GitHub Issues.
    
    \item \textbf{Τεχνική τεκμηρίωση:} README files, documentation pages, 
    API references, και technical specifications.
    
    \item \textbf{Συζητήσεις κοινότητας:} Δεδομένα από Stack Overflow, 
    mailing lists, και άλλες πλατφόρμες επικοινωνίας προγραμματιστών.
    
    \item \textbf{Άλλοι τύποι:} Dockerfiles, Jupyter notebooks, κείμενα 
    αδειών χρήσης, και άλλα εξειδικευμένα τεχνικά έγγραφα.
\end{itemize}

\subsection{Επιλογή συνόλου δεδομένων}
\label{subsection:dataset_selection}

Από το ευρύτερο directory datasets του MSR conference \cite{diamantopoulos2025directory}, επιλέχθηκε το σύνολο δεδομένων SOSum: A dataset of extractive summaries of Stack Overflow posts and associated labeling tools\cite{kou2022sosum}, με FAIR score: $27.08\%$ για την αξιολόγηση 
του προτεινόμενου συστήματος. Το SOSum αποτελεί ένα dataset που περιλαμβάνει 
2,278 δημοφιλείς αναρτήσεις-απαντήσεις από το Stack Overflow με χειροκίνητα 
επισημειωμένες περιληπτικές προτάσεις. Οι ερωτήσεις στο SOSum καλύπτουν 669 
διαφορετικά tags με διάμεσο αριθμό προβολών 253K και διάμεσο post score 17, 
αντανακλώντας υψηλής ποιότητας τεχνικό περιεχόμενο.

\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{images/chapter5/dataset_overview.png}
    \caption{Το σύνολο δεδομένων SOSum περιληπτικά}
    \label{fig:dataset}
\end{figure}
\begin{figure}[H]
    \centering
    \includegraphics[width=1\linewidth]{images/chapter5/text_length_distributions.png}
    \caption{Κατανομή μήκους κειμένου ερωτήσεων και απαντήσεων στο σύνολο δεδομένων}
    \label{fig:text_length_distribution}
\end{figure}
\subsubsection*{Κριτήρια Επιλογής}
Η επιλογή του \textbf{SOSum dataset} βασίστηκε σε τρεις κύριους λόγους που το καθιστούν κατάλληλο για την αξιολόγηση συστημάτων RAG στον τομέα της τεχνολογίας λογισμικού. Πρώτον, περιλαμβάνει \textbf{πυκνό σύνολο τεχνικών ερωτήσεων και απαντήσεων} που αντικατοπτρίζουν ρεαλιστικές πληροφοριακές ανάγκες προγραμματιστών σε ποικιλία γλωσσών, εργαλείων και πλαισίων. Δεύτερον, η \textbf{δομή του dataset} ευνοεί την ανάπτυξη συστημάτων ερώτησης–απάντησης, καθώς κάθε ερώτηση συνοδεύεται από πολλαπλές απαντήσεις διαφορετικής ποιότητας και λεπτομέρειας, ενώ οι \textit{χειροκίνητες επισημειώσεις} παρέχουν αντικειμενικό μέτρο αξιολόγησης. Τρίτον, παρέχεται σε \textbf{δομημένη μορφή με πλήρη μεταδεδομένα}, διευκολύνοντας την ενσωμάτωσή του στο σύστημα χωρίς ανάγκη εκτεταμένης προεπεξεργασίας ή καθαρισμού δεδομένων.


\subsubsection*{Περιορισμοί και Προκλήσεις}

Παρά τα πλεονεκτήματά του, το \textbf{SOSum dataset} παρουσιάζει έναν βασικό περιορισμό που επηρεάζει την αξιολόγηση του συστήματος. Οι απαντήσεις του Stack Overflow κατατάσσονται μέσω προεπιλεγμένης σειράς κατάταξης του Stack Exchange, το οποίο βασίζεται κυρίως στη \textit{ψηφοφορία της κοινότητας} και στην \textit{αποδοχή από τον ερωτώντα}. Ωστόσο, η κατάταξη αυτή δεν αποτελεί πάντα πραγματική σημασιολογική ταξινόμηση, καθώς επηρεάζεται από παράγοντες όπως ο χρόνος δημοσίευσης, η φήμη του χρήστη και η σαφήνεια της διατύπωσης, ανεξάρτητα από την τεχνική πληρότητα της απάντησης. Αυτό δυσχεραίνει την εφαρμογή \textit{rank-aware} μετρικών αξιολόγησης, όπως το \textbf{Normalized Discounted Cumulative Gain (NDCG)}, καθώς δεν είναι εγγυημένο ότι η πρώτη απάντηση αντιστοιχεί στην πιο σχετική. Παρά τον θόρυβο που εισάγει αυτή η αβεβαιότητα, η χρήση πραγματικών δεδομένων με τις εγγενείς τους ατέλειες θεωρείται προτιμότερη από τεχνητά benchmarks, καθώς αποτυπώνει πιο ρεαλιστικά τις συνθήκες παραγωγικής χρήσης.

\section{Διεξαγωγή Πειραμάτων}
% στο preamble:
\hypersetup{colorlinks=true, linkcolor=black, urlcolor=blue}
Η σειρά πειραμάτων που θα ακολουθήσει επιδιώκει να απαντήσει στα εξής ερευνητικά ερωτήματα. α) Ποιες είναι οι επιλογές ανάκτησης και από αυτές ποιες αποδίδουν καλύτερα στο σύνολο δεδομένων; β) έχοντας ένα σημείο αναφοράς, γίνεται να βελτιωθούν οι επιδώσεις με κατάλληλη επιλογή υπερπαραμέτρων; γ) πόσο βοήθησε το σύστημα ανάκτησης την παραγωγή απαντήσεων και κατά συνέπεια τον τελικό χρήστη; Όλα τα πειράματα εκτελέστηκαν στο ίδιο υπολογιστικό περιβάλλον, ώστε να διασφαλιστούν η συγκρισιμότητα και η αναπαραγωγιμότητα.
\subsubsection*{Υπολογιστικό περιβάλλον}
\begin{table}[h!]
  \centering
  \small
  \begin{tabular}{@{}ll@{}}
    \toprule
    \textbf{Στοιχείο} & \textbf{Περιγραφή} \\
    \midrule
    Επεξεργαστής & AMD Ryzen 7 2700X (8~πυρήνες, 16~threads) \\[2pt]
    Κάρτα Γραφικών & NVIDIA GTX 1080\,8GB \\[2pt]
    Μνήμη & 32\,GB DDR4 RAM \\[2pt]
    Αποθήκευση & SSD NVMe 1\,TB \\[2pt]
    Λειτουργικό σύστημα & Manjaro Linux \\[2pt]
    \bottomrule
  \end{tabular}
  \caption{Προδιαγραφές του υπολογιστικού περιβάλλοντος που χρησιμοποιήθηκε για τη διεξαγωγή των πειραμάτων.}
  \label{tab:hardware_specs}
\end{table}
*Υποσημείωση: η κάρτα γραφικών χρησιμοποιήθηκε μόνο στο πείραμα 3.

\subsubsection*{Λογισμικό και ρυθμίσεις}

Η υλοποίηση έγινε σε \textbf{Python~3.13.7}. 
Για τη δημιουργία και ανάκτηση των διανυσματικών αναπαραστάσεων 
χρησιμοποιήθηκαν αποκλειστικά \textbf{ανοιχτού κώδικα και τοπικές (local) ενσωματώσεις}, 
χωρίς κόστος API κλήσεων. Συγκεκριμένα, χρησιμοποιήθηκαν τα εξής μοντέλα:

\begin{table}[H]
  \centering
  \small
  \begin{tabular}{@{}ll@{}}
    \toprule
    \textbf{Κατηγορία} & \textbf{Περιγραφή / Τιμή} \\
    \midrule
    Πυκνές ενσωματώσεις & \href{https://huggingface.co/BAAI/bge-m3}{\texttt{BAAI/bge-m3}}\cite{chen2024bge} \\[2pt]
    Αραίες ενσωματώσεις επέκτασης & \href{https://huggingface.co/prithivida/Splade_PP_en_v1}{\texttt{prithivida/Splade\_PP\_en\_v1}}\cite{damodaran2024splade} \\[2pt]
    Αραιές ενσωματώσεις & \texttt{BM25} \\[2pt]
    \midrule
    \textit{top-$k$} & 10 \\[2pt]
    Μέγεθος τμημάτων & 500 tokens \\[2pt]
    Επικάλυψη τμημάτων & 100 tokens \\[2pt]
    Στρατηγική τμηματοποίησης & Αναδρομικός διαχωρισμός χαρακτήρων \\[2pt]
    Διάσταση Πυκνών Ενσωματώσεων & 1024\\[2pt]
    \midrule
    Έκδοση Python & 3.13.7 \\[2pt]
    \bottomrule
  \end{tabular}
  \caption{Ρυθμίσεις λογισμικού και παραμέτρων του πειραματικού περιβάλλοντος.}
  \label{tab:software_settings}
\end{table}

Η παράμετρος \textbf{top-k} ορίστηκε $k=10$ για όλα τα πειράματα. Για την εισαγωγή δεδομένων χρησιμοποιήθηκε  μέγεθος τμήματος \textbf{500 tokens} με αλληλοεπικάλυψη \textbf{100 tokens} και με στρατηγική \textbf{αναδρομικού διαχωρισμού χαρακτήρων} (recursive character splitting). Οι συγκεκριμένες τιμές βρέθηκαν εμπειρικά να προσφέρουν καλή ισορροπία μεταξύ ακρίβειας ανάκτησης και υπολογιστικής αποδοτικότητας στο σύνολο δεδομένων SOSum. Η σταθερότητα των αποτελεσμάτων διασφαλίστηκε με κοινές ρυθμίσεις σε όλους τους retrievers 
και σταθερό random seed. 

